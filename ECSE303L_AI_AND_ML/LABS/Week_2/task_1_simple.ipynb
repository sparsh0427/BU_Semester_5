{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression\n",
    "Linear regression is among the simplest regression methods. One of the main advantages of using it is ease of interpreting results. Simple linear regression is special case of regression where target feature is dependent on single variable, and then we find the best fitting line.<br>\n",
    "\n",
    "##### y = m*x + c <br>\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at __\"data/simple_linear_data.csv\"__ in the respective challenge's repo.<br><br>\n",
    "This is the modified version of the dataset 'Student Performance' provided by UCI Machine Learning repository.<br>\n",
    "Original dataset: https://archive.ics.uci.edu/ml/datasets/student+performance\n",
    "\n",
    "#### Features (X)\n",
    "- G2 - second year math grades (numeric: from 0 to 100)\n",
    "\n",
    "#### Target (y)\n",
    "- G3 - third year math grades (numeric: from 0 to 100, output target)\n",
    "\n",
    "#### Objective\n",
    "To gain understanding of single linear regression through implementing the model from scratch\n",
    "\n",
    "#### Tasks\n",
    "- Read the data from above mentioned dataset and define X and y as numpy array\n",
    "- Add column at position 0 with all values=1 (pandas.DataFrame.insert function)\n",
    "- Print rows from 40 to 55.\n",
    "- Print the shape and datatype of both X and y\n",
    "- Follow code cells to implement simple linear regression from scratch\n",
    "    - Write hypothesis function to predict values\n",
    "    - Write function for calculating mean_squared_error\n",
    "    - Write function to return gradients for given weights\n",
    "    - Perform gradient descent taking help of above functions\n",
    "\n",
    "#### Further Fun (will not be evaluated\n",
    "- Remove outliers, train again and see the difference in error.\n",
    "```python\n",
    "# Add this line before defining X and y\n",
    "data = data[(data['G3']!=0)|((data['G2']==0)&(data['G3']==0))]\n",
    "```\n",
    "- Replace \"*weights = np.random.rand(2)*\" line in gradient descent with below line, train again and visualize results.\n",
    "```python\n",
    "# Replace above line with following in gradient descent function\n",
    "weights = np.zeros(2,)\n",
    "```\n",
    "- Play with learning rate and max_iterations\n",
    "- Generalize the code for multivariate(multiple) linear regression\n",
    "\n",
    "#### Resources\n",
    "- Linear regression maths: https://www.youtube.com/watch?v=ZkjP5RJLQF4\n",
    "- Simple linear regression: https://www.youtube.com/watch?v=iAgYLRy7e20\n",
    "- Tutorial: https://machinelearningmastery.com/implement-simple-linear-regression-scratch-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from provided dir\n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column which has all 1s\n",
    "# The idea is that weight corresponding to this column is equal to intercept\n",
    "# This way it is efficient and easier to handle the bias/intercept term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataframe rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X (input features) and y (output feature) \n",
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shape = \n",
    "X_type  = \n",
    "y_shape = \n",
    "y_type  = \n",
    "print(f'X: Type-{X_type}, Shape-{X_shape}')\n",
    "print(f'y: Type-{y_type}, Shape-{y_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Expected output__:<br><br>\n",
    "X: Type-<class 'numpy.ndarray'>, Shape-(395,2)<br>\n",
    "y: Type-<class 'numpy.ndarray'>, Shape-(395,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the relationship between X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CODE CELL\n",
    "plt.scatter(X[:,1],y)\n",
    "plt.title('Relation between second year grades and third year grades')\n",
    "plt.xlabel('G2 (X - Second year grades)')\n",
    "plt.ylabel('G3 (Y - Third year grades)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let us start implementing linear regression from scratch. Just follow code cells, see hints if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    '''\n",
    "    weights   : array (2,1) w0 and w1\n",
    "    X         : array (m,2) x0 (intercept=1) and x1\n",
    "    \n",
    "    Returns predicted y using hyothesis linear function defined by given weights\n",
    "    '''\n",
    "    ### START CODE HERE ###\n",
    "    y_pred = \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert (y_pred.shape==(X.shape[0],)), 'Wrong implementation of predict function. Check carefully'\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred) : \n",
    "    '''\n",
    "    y_true : (m,1)\n",
    "    y_pred : (m,1)\n",
    "    \n",
    "    Return the mean squared error\n",
    "    '''\n",
    "    ### START CODE HERE ###\n",
    "    loss = \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, y_true, y_pred):\n",
    "    '''\n",
    "    X      : array (m,2)\n",
    "    y_true : array (m,1)\n",
    "    y_pred : array (m,1)\n",
    "    \n",
    "    Returns a numpy array with gradients. Shape (2,1)\n",
    "    '''\n",
    "    # Initialize the gradient vector for w0 (intercept/bias) and w1 respectively\n",
    "    grad = np.zeros(2,)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    grad[0] = \n",
    "    grad[1] = \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, learning_rate=0.01, max_iterations=100):\n",
    "    '''\n",
    "    X              : Array (m,2)\n",
    "    y              : Array (m,1)\n",
    "    learning_rate  : Learning rate\n",
    "    max_iterations : Maximum iteratons\n",
    "    \n",
    "    Returns : weights vector (2,1)\n",
    "            : losses (List)\n",
    "    '''\n",
    "    # Initialise weights vector of random values of size (2,1)\n",
    "    weights = np.random.rand(2)\n",
    "    # Initialize a list to record all the losses \n",
    "    losses  = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return weights, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Congratulations! You have implemented linear regression from scratch. Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gradient descent\n",
    "optimal_weights, losses = gradient_descent(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THE FOLLOWING CODE CELLS\n",
    "# Print final loss\n",
    "print(\"Mean squared error:\", losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot([i for i in range(len(losses))], losses)\n",
    "plt.title(\"Loss curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using trained weights\n",
    "y_pred = hypothesis(X, optimal_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results by plotting it\n",
    "plt.scatter(X[:,1], y, c='r', label='Actual scores')\n",
    "plt.plot(X[:,1], y_pred, c='g', label='Fitted line | predictions')\n",
    "plt.legend()\n",
    "plt.title(\"Linear regression fitted line\")\n",
    "plt.xlabel(\"Second year grades\")\n",
    "plt.ylabel(\"Third year grades\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
