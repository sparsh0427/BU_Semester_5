{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMHjtVPbyaKP"
   },
   "source": [
    "## Logistic Regression Model for Divorce Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: Implement  linear regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJi26z8awmSD"
   },
   "source": [
    "### Logistic regression\n",
    "Logistic regression uses an equation as the representation, very much like linear regression.\n",
    "\n",
    "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
    "\n",
    "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at <strong>\"data/divorce.csv\"</strong> in the respective challenge's repo.<br>\n",
    "<strong>Original Source:</strong> https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set. Dataset is based on rating for questionnaire filled by people who already got divorse and those who is happily married.<br><br>\n",
    "\n",
    "[//]: # \"The dataset is available at http://archive.ics.uci.edu/ml/machine-learning-databases/00520/data.zip. Unzip the file and use either CSV or xlsx file.<br>\"\n",
    "\n",
    "\n",
    "#### Features (X)\n",
    "1. Atr1 - If one of us apologizes when our discussion deteriorates, the discussion ends. (Numeric | Range: 0-4)\n",
    "2. Atr2 - I know we can ignore our differences, even if things get hard sometimes. (Numeric | Range: 0-4)\n",
    "3. Atr3 - When we need it, we can take our discussions with my spouse from the beginning and correct it. (Numeric | Range: 0-4)\n",
    "4. Atr4 - When I discuss with my spouse, to contact him will eventually work. (Numeric | Range: 0-4)\n",
    "5. Atr5 - The time I spent with my wife is special for us. (Numeric | Range: 0-4)\n",
    "6. Atr6 - We don't have time at home as partners. (Numeric | Range: 0-4)\n",
    "7. Atr7 - We are like two strangers who share the same environment at home rather than family. (Numeric | Range: 0-4)\n",
    "\n",
    "&emsp;.<br>\n",
    "&emsp;.<br>\n",
    "&emsp;.<br>\n",
    "<br>\n",
    "54. Atr54 - I'm not afraid to tell my spouse about her/his incompetence. (Numeric | Range: 0-4)\n",
    "<br><br>\n",
    "Take a look above at the source of the original dataset for more details.\n",
    "\n",
    "#### Target (y)\n",
    "55. Class: (Binary | 1 => Divorced, 0 => Not divorced yet)\n",
    "\n",
    "#### Objective\n",
    "To gain understanding of logistic regression through implementing the model from scratch\n",
    "\n",
    "#### Tasks\n",
    "- Download and load the data (csv file contains ';' as delimiter)\n",
    "- Add column at position 0 with all values=1 (pandas.DataFrame.insert function). This is for input to the bias $w_0$\n",
    "- Define X matrix (independent features) and y vector (target feature) as numpy arrays\n",
    "- Print the shape and datatype of both X and y\n",
    "[//]: # \"- Dataset contains missing values, hence fill the missing values (NA) by performing missing value prediction\"\n",
    "[//]: # \"- Since the all the features are in higher range, columns can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (sklearn.preprocessing.StandardScaler)\"\n",
    "- Split the dataset into 85% for training and rest 15% for testing (sklearn.model_selection.train_test_split function)\n",
    "- Follow logistic regression class and fill code where highlighted:\n",
    "    - Write sigmoid function to predict probabilities\n",
    "    - Write log likelihood function\n",
    "    - Write fit function where gradient ascent is implemented\n",
    "    - Write predict_proba function where we predict probabilities for input data\n",
    "- Train the model\n",
    "- Write function for calculating accuracy\n",
    "- Compute accuracy on train and test data\n",
    "\n",
    "#### Further Fun (will not be evaluated)\n",
    "- Play with learning rate and max_iterations\n",
    "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
    "- Train model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
    "- Shuffle training samples with different random seed values in the train_test_split function. Check the model error for the testing data for each setup.\n",
    "- Print other classification metrics such as:\n",
    "    - classification report (sklearn.metrics.classification_report),\n",
    "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
    "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
    "\n",
    "#### Helpful links\n",
    "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
    "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21J6cpd_wmSE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SL1fdNt1k3Q"
   },
   "outputs": [],
   "source": [
    "# Download the dataset from the source\n",
    "!wget _URL_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9av7W-wowmSI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  Atr10  ...  Atr46  \\\n",
       "0       2     2     4     1     0     0     0     0     0      0  ...      2   \n",
       "1       4     4     4     4     4     0     0     4     4      4  ...      2   \n",
       "2       2     2     2     2     1     3     2     1     1      2  ...      3   \n",
       "3       3     2     3     2     3     3     3     3     3      3  ...      2   \n",
       "4       2     2     1     1     1     1     0     0     0      0  ...      2   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...    ...   \n",
       "165     0     0     0     0     0     0     0     0     0      0  ...      1   \n",
       "166     0     0     0     0     0     0     0     0     0      0  ...      4   \n",
       "167     1     1     0     0     0     0     0     0     0      1  ...      3   \n",
       "168     0     0     0     0     0     0     0     0     0      0  ...      3   \n",
       "169     0     0     0     0     0     0     0     1     0      0  ...      3   \n",
       "\n",
       "     Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0        1      3      3      3      2      3      2      1      1  \n",
       "1        2      3      4      4      4      4      2      2      1  \n",
       "2        2      3      1      1      1      2      2      2      1  \n",
       "3        2      3      3      3      3      2      2      2      1  \n",
       "4        1      2      3      2      2      2      1      0      1  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "165      0      4      1      1      4      2      2      2      0  \n",
       "166      1      2      2      2      2      3      2      2      0  \n",
       "167      0      2      0      1      1      3      0      0      0  \n",
       "168      3      2      2      3      2      4      3      1      0  \n",
       "169      4      4      0      1      3      3      3      1      0  \n",
       "\n",
       "[170 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from local cloud directory\n",
    "data = pd.read_csv('data/divorce.csv', delimiter=';'  , engine='python') \n",
    "data\n",
    "# Set delimiter to semicolon(;) in case of unexpected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_0  Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  ...  Atr46  \\\n",
       "0      1     2     2     4     1     0     0     0     0     0  ...      2   \n",
       "1      1     4     4     4     4     4     0     0     4     4  ...      2   \n",
       "2      1     2     2     2     2     1     3     2     1     1  ...      3   \n",
       "3      1     3     2     3     2     3     3     3     3     3  ...      2   \n",
       "4      1     2     2     1     1     1     1     0     0     0  ...      2   \n",
       "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "165    1     0     0     0     0     0     0     0     0     0  ...      1   \n",
       "166    1     0     0     0     0     0     0     0     0     0  ...      4   \n",
       "167    1     1     1     0     0     0     0     0     0     0  ...      3   \n",
       "168    1     0     0     0     0     0     0     0     0     0  ...      3   \n",
       "169    1     0     0     0     0     0     0     0     1     0  ...      3   \n",
       "\n",
       "     Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0        1      3      3      3      2      3      2      1      1  \n",
       "1        2      3      4      4      4      4      2      2      1  \n",
       "2        2      3      1      1      1      2      2      2      1  \n",
       "3        2      3      3      3      3      2      2      2      1  \n",
       "4        1      2      3      2      2      2      1      0      1  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "165      0      4      1      1      4      2      2      2      0  \n",
       "166      1      2      2      2      2      3      2      2      0  \n",
       "167      0      2      0      1      1      3      0      0      0  \n",
       "168      3      2      2      3      2      4      3      1      0  \n",
       "169      4      4      0      1      3      3      3      1      0  \n",
       "\n",
       "[170 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column which has all 1s\n",
    "# The idea is that weight corresponding to this column is equal to intercept\n",
    "# This way it is efficient and easier to handle the bias/intercept term\n",
    "data.insert(0,'x_0',[1] * data.shape[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eV1jGAQxwmSP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_0  Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  ...  Atr46  \\\n",
       "0    1     2     2     4     1     0     0     0     0     0  ...      2   \n",
       "1    1     4     4     4     4     4     0     0     4     4  ...      2   \n",
       "2    1     2     2     2     2     1     3     2     1     1  ...      3   \n",
       "3    1     3     2     3     2     3     3     3     3     3  ...      2   \n",
       "4    1     2     2     1     1     1     1     0     0     0  ...      2   \n",
       "\n",
       "   Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0      1      3      3      3      2      3      2      1      1  \n",
       "1      2      3      4      4      4      4      2      2      1  \n",
       "2      2      3      1      1      1      2      2      2      1  \n",
       "3      2      3      3      3      3      2      2      2      1  \n",
       "4      1      2      3      2      2      2      1      0      1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dataframe rows just to see some samples\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joRU6dWxwmSR"
   },
   "outputs": [],
   "source": [
    "# Define X (input features) and y (output feature) \n",
    "X = data.iloc[:,0:55].values\n",
    "y = data['Class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAyM-CYCwmSU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)\n",
      "y: Type-<class 'numpy.ndarray'>, Shape-(170,)\n"
     ]
    }
   ],
   "source": [
    "X_shape = X.shape\n",
    "X_type  = type(X)\n",
    "y_shape = y.shape\n",
    "y_type  = type(y)\n",
    "print(f'X: Type-{X_type}, Shape-{X_shape}')\n",
    "print(f'y: Type-{y_type}, Shape-{y_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Expected output: </strong><br><br>\n",
    "\n",
    "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)<br>\n",
    "y: Type-<class 'numpy.ndarray'>, Shape-(170,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdLIVOm127-z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and fill any missing values if any\n",
    "is_missing_values = data.isnull()\n",
    "(is_missing_values.values == True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En9Kb9dh2-wm"
   },
   "outputs": [],
   "source": [
    "# Perform standarization (if required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8WF-EqO3BEa"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acCATJhI3FdH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (144, 55) , y_train: (144,)\n",
      "X_test: (26, 55) , y_test: (26,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of features and target of training and testing: X_train, X_test, y_train, y_test\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "X_test_shape  = X_test.shape\n",
    "y_test_shape  = y_test.shape\n",
    "\n",
    "print(f\"X_train: {X_train_shape} , y_train: {y_train_shape}\")\n",
    "print(f\"X_test: {X_test_shape} , y_test: {y_test_shape}\")\n",
    "assert (X_train.shape[0]==y_train.shape[0] and X_test.shape[0]==y_test.shape[0]), \"Check your splitting carefully\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSa7cW-NwmSd"
   },
   "source": [
    "##### Let us start implementing logistic regression from scratch. Just follow code cells, see hints if required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will build a LogisticRegression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT ANY VARIABLE OR FUNCTION NAME(S) IN THIS CELL\n",
    "# Let's try more object oriented approach this time :)\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, max_iterations=100):\n",
    "        '''Initialize variables\n",
    "        Args:\n",
    "            learning_rate  : Learning Rate\n",
    "            max_iterations : Max iterations for training weights\n",
    "        '''\n",
    "        # Initialising all the parameters\n",
    "        self.learning_rate  = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.likelihoods    = []\n",
    "        \n",
    "        # Define epsilon because log(0) is not defined\n",
    "        self.eps = 1e-7\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        '''Sigmoid function: f:R->(0,1)\n",
    "        Args:\n",
    "            z : A numpy array (num_samples,)\n",
    "        Returns:\n",
    "            A numpy array where sigmoid function applied to every element\n",
    "        '''\n",
    "        ### START CODE HERE\n",
    "        sig_z = 1/(1 + np.exp(-z))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
    "        return sig_z\n",
    "    \n",
    "    def log_likelihood(self, y_true, y_pred):\n",
    "        '''Calculates maximum likelihood estimate\n",
    "        Remember: y * log(yh) + (1-y) * log(1-yh)\n",
    "        Note: Likelihood is defined for multiple classes as well, but for this dataset\n",
    "        we only need to worry about binary/bernoulli likelihood function\n",
    "        Args:\n",
    "            y_true : Numpy array of actual truth values (num_samples,)\n",
    "            y_pred : Numpy array of predicted values (num_samples,)\n",
    "        Returns:\n",
    "            Log-likelihood, scalar value\n",
    "        '''\n",
    "        # Fix 0/1 values in y_pred so that log is not undefined\n",
    "        y_pred = np.maximum(np.full(y_pred.shape, self.eps), np.minimum(np.full(y_pred.shape, 1-self.eps), y_pred))\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        likelihood = (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return likelihood\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''Trains logistic regression model using gradient ascent\n",
    "        to gain maximum likelihood on the training data\n",
    "        Args:\n",
    "            X : Numpy array (num_examples, num_features)\n",
    "            y : Numpy array (num_examples, )\n",
    "        Returns: VOID\n",
    "        '''\n",
    "        \n",
    "        num_examples = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        \n",
    "        # Initialize weights with appropriate shape\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # Perform gradient ascent\n",
    "        for i in range(self.max_iterations):\n",
    "            # Define the linear hypothesis(z) first\n",
    "            # HINT: what is our hypothesis function in linear regression, remember?\n",
    "            z = np.dot(X,self.weights)\n",
    "            \n",
    "            # Output probability value by appplying sigmoid on z\n",
    "            y_pred = self.sigmoid(z)\n",
    "            \n",
    "            # Calculate the gradient values\n",
    "            # This is just vectorized efficient way of implementing gradient. Don't worry, we will discuss it later.\n",
    "            gradient = np.mean((y-y_pred)*X.T, axis=1)\n",
    "            \n",
    "            # Update the weights\n",
    "            # Caution: It is gradient ASCENT not descent\n",
    "            self.weights = self.weights + gradient\n",
    "            \n",
    "            # Calculating log likelihood\n",
    "            likelihood = self.log_likelihood(y,y_pred)\n",
    "\n",
    "            self.likelihoods.append(likelihood)\n",
    "    \n",
    "        ### END CODE HERE\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''Predict probabilities for given X.\n",
    "        Remember sigmoid returns value between 0 and 1.\n",
    "        Args:\n",
    "            X : Numpy array (num_samples, num_features)\n",
    "        Returns:\n",
    "            probabilities: Numpy array (num_samples,)\n",
    "        '''\n",
    "        if self.weights is None:\n",
    "            raise Exception(\"Fit the model before prediction\")\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        z = np.dot(X,self.weights)\n",
    "        probabilities = self.sigmoid(z)\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        '''Predict/Classify X in classes\n",
    "        Args:\n",
    "            X         : Numpy array (num_samples, num_features)\n",
    "            threshold : scalar value above which prediction is 1 else 0\n",
    "        Returns:\n",
    "            binary_predictions : Numpy array (num_samples,)\n",
    "        '''\n",
    "        # Thresholding probability to predict binary values\n",
    "#         binary_predictions = self.predict_proba(X).applymap(lambda x: 1 if x>threshold else 0)\n",
    "        binary_predictions = np.array(list(map(lambda x: 1 if x>threshold else 0, self.predict_proba(X))))\n",
    "        \n",
    "        return binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now initialize logitic regression implemented by you\n",
    "model = MyLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now fit on training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phew!! That's a lot of code. But you did it, congrats !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tvMc0OqwmSp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on training data: [-1.00000005e-07 -3.54775387e-05 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -2.96506230e-07 -7.20928494e-05\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -9.01259205e-03\n",
      " -1.69330170e-03 -2.33131686e-03 -6.67224688e-03 -4.86121723e-04\n",
      " -1.00000005e-07 -5.67325405e-02 -1.00000005e-07 -3.51393418e-04\n",
      " -1.00000005e-07 -1.00000005e-07 -2.03160581e-02 -1.00000005e-07\n",
      " -1.20619472e-04 -5.51268810e-02 -2.54716424e-04 -1.00000005e-07\n",
      " -1.00000005e-07 -1.75794408e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -9.06612178e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -9.54400797e-02 -3.56801659e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -5.46286690e-05 -4.21666198e-06 -1.00000005e-07 -2.75619687e-05\n",
      " -5.94653315e-07 -1.35365144e-01 -2.03160581e-02 -4.32980208e-03\n",
      " -1.00000005e-07 -1.00000005e-07 -3.36655225e-04 -1.00000005e-07\n",
      " -1.00000005e-07 -2.48738174e-04 -1.00000005e-07 -1.00000005e-07\n",
      " -1.39285210e-05 -1.00000005e-07 -1.00000005e-07 -4.40354377e-02\n",
      " -1.00000005e-07 -1.59730203e-02 -5.43203304e-03 -1.15564982e-05\n",
      " -2.57661989e-05 -1.23625839e-03 -1.00000005e-07 -2.00018081e-02\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.25058865e-04\n",
      " -1.11491884e-07 -4.94029342e-06 -1.00000005e-07 -6.02528906e-05\n",
      " -1.08659653e-05 -3.02585181e-03 -1.00000005e-07 -7.23151585e-02\n",
      " -2.84757897e-05 -1.00000005e-07 -5.29281055e-04 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.26641534e-02 -4.51785471e-04 -4.56384686e-05 -1.00000005e-07\n",
      " -5.07396533e-05 -1.08754261e-02 -6.80985094e-02 -1.00000005e-07\n",
      " -1.95928867e-07 -1.74375721e-02 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.18503573e-02 -1.00000005e-07 -1.00000005e-07\n",
      " -2.29309551e-04 -2.62961790e-06 -5.99154812e-02 -3.81334518e-03\n",
      " -1.00000005e-07 -1.00000005e-07 -1.99196085e-05 -1.00000005e-07\n",
      " -2.07709112e-02 -1.00000005e-07 -1.00000005e-07 -4.94922440e-02\n",
      " -1.00000005e-07 -1.00000005e-07 -1.67510419e-03 -4.04435092e-07\n",
      " -1.00000005e-07 -3.62044388e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -2.20043770e-07 -4.25270931e-02 -1.10855783e-03 -1.40267440e-04\n",
      " -4.31354641e-03 -3.92808143e-06 -8.27280799e-05 -1.00000005e-07\n",
      " -6.48652088e-03 -1.16582818e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -1.41800962e-02 -1.68367851e-05]\n"
     ]
    }
   ],
   "source": [
    "# Train log-likelihood\n",
    "train_log_likelihood = model.log_likelihood(y_train, model.predict_proba(X_train))\n",
    "print(\"Log-likelihood on training data:\", train_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZQ8ITUt4b0N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on testing data: [-1.57921075e-04 -1.00000005e-07 -1.14483744e-04 -1.00000005e-07\n",
      " -1.01880528e-02 -2.83341217e-03 -4.10688283e-05 -1.00000005e-07\n",
      " -3.86791638e-03 -1.00000005e-07 -1.00000005e-07 -2.26199442e-02\n",
      " -1.10491278e-04 -1.00000005e-07 -1.00000005e-07 -1.38941419e-03\n",
      " -1.00000005e-07 -3.13460849e-06 -1.00000005e-07 -1.18948235e-03\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -2.53645941e-01]\n"
     ]
    }
   ],
   "source": [
    "# Test log-likelihood\n",
    "test_log_likelihood = model.log_likelihood(y_test, model.predict_proba(X_test))\n",
    "print(\"Log-likelihood on testing data:\", test_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot([i+1 for i in range(len(model.likelihoods))], model.likelihoods)\n",
    "plt.title(\"Log-Likelihood curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Log-likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's calculate accuracy as well. Accuracy is defined simply as the rate of correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    '''Compute accuracy.\n",
    "    Accuracy = (Correct prediction / number of samples)\n",
    "    Args:\n",
    "        y_true : Truth binary values (num_examples, )\n",
    "        y_pred : Predicted binary values (num_examples, )\n",
    "    Returns:\n",
    "        accuracy: scalar value\n",
    "    '''\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    accuracy = np.equal(y_true,y_pred).mean()\n",
    "#     print(accuracy)\n",
    "    ### END CODE HERE\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on train data\n",
    "y_pred = model.predict(X_train)\n",
    "print(accuracy(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on test data\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2: Use Logistic Regression from sklearn on the same dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "- Define X and y again for sklearn Linear Regression model\n",
    "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
    "- Run the model on testing set\n",
    "- Print 'accuracy' obtained on the testing dataset (sklearn.metrics.accuracy_score function)\n",
    "\n",
    "#### Further fun (will not be evaluated)\n",
    "- Compare accuracies of your model and sklearn's logistic regression model\n",
    "\n",
    "#### Helpful links\n",
    "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  Atr10  ...  Atr46  \\\n",
       "0       2     2     4     1     0     0     0     0     0      0  ...      2   \n",
       "1       4     4     4     4     4     0     0     4     4      4  ...      2   \n",
       "2       2     2     2     2     1     3     2     1     1      2  ...      3   \n",
       "3       3     2     3     2     3     3     3     3     3      3  ...      2   \n",
       "4       2     2     1     1     1     1     0     0     0      0  ...      2   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...    ...   \n",
       "165     0     0     0     0     0     0     0     0     0      0  ...      1   \n",
       "166     0     0     0     0     0     0     0     0     0      0  ...      4   \n",
       "167     1     1     0     0     0     0     0     0     0      1  ...      3   \n",
       "168     0     0     0     0     0     0     0     0     0      0  ...      3   \n",
       "169     0     0     0     0     0     0     0     1     0      0  ...      3   \n",
       "\n",
       "     Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0        1      3      3      3      2      3      2      1      1  \n",
       "1        2      3      4      4      4      4      2      2      1  \n",
       "2        2      3      1      1      1      2      2      2      1  \n",
       "3        2      3      3      3      3      2      2      2      1  \n",
       "4        1      2      3      2      2      2      1      0      1  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "165      0      4      1      1      4      2      2      2      0  \n",
       "166      1      2      2      2      2      3      2      2      0  \n",
       "167      0      2      0      1      1      3      0      0      0  \n",
       "168      3      2      2      3      2      4      3      1      0  \n",
       "169      4      4      0      1      3      3      3      1      0  \n",
       "\n",
       "[170 rows x 55 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/divorce.csv', delimiter=';'  , engine='python') \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = data.iloc[:,0:54].values\n",
    "y = data['Class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model from sklearn\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on testing set X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on testing set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy on testing set\n",
    "test_accuracy_sklearn = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nAccuracy on testing set: {test_accuracy_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task_1_logistic_divorse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
