{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMHjtVPbyaKP"
   },
   "source": [
    "## Logistic Regression Model for Divorce Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: Implement  linear regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJi26z8awmSD"
   },
   "source": [
    "### Logistic regression\n",
    "Logistic regression uses an equation as the representation, very much like linear regression.\n",
    "\n",
    "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
    "\n",
    "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at <strong>\"data/divorce.csv\"</strong> in the respective challenge's repo.<br>\n",
    "<strong>Original Source:</strong> https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set. Dataset is based on rating for questionnaire filled by people who already got divorse and those who is happily married.<br><br>\n",
    "\n",
    "[//]: # \"The dataset is available at http://archive.ics.uci.edu/ml/machine-learning-databases/00520/data.zip. Unzip the file and use either CSV or xlsx file.<br>\"\n",
    "\n",
    "\n",
    "#### Features (X)\n",
    "1. Atr1 - If one of us apologizes when our discussion deteriorates, the discussion ends. (Numeric | Range: 0-4)\n",
    "2. Atr2 - I know we can ignore our differences, even if things get hard sometimes. (Numeric | Range: 0-4)\n",
    "3. Atr3 - When we need it, we can take our discussions with my spouse from the beginning and correct it. (Numeric | Range: 0-4)\n",
    "4. Atr4 - When I discuss with my spouse, to contact him will eventually work. (Numeric | Range: 0-4)\n",
    "5. Atr5 - The time I spent with my wife is special for us. (Numeric | Range: 0-4)\n",
    "6. Atr6 - We don't have time at home as partners. (Numeric | Range: 0-4)\n",
    "7. Atr7 - We are like two strangers who share the same environment at home rather than family. (Numeric | Range: 0-4)\n",
    "\n",
    "&emsp;.<br>\n",
    "&emsp;.<br>\n",
    "&emsp;.<br>\n",
    "<br>\n",
    "54. Atr54 - I'm not afraid to tell my spouse about her/his incompetence. (Numeric | Range: 0-4)\n",
    "<br><br>\n",
    "Take a look above at the source of the original dataset for more details.\n",
    "\n",
    "#### Target (y)\n",
    "55. Class: (Binary | 1 => Divorced, 0 => Not divorced yet)\n",
    "\n",
    "#### Objective\n",
    "To gain understanding of logistic regression through implementing the model from scratch\n",
    "\n",
    "#### Tasks\n",
    "- Download and load the data (csv file contains ';' as delimiter)\n",
    "- Add column at position 0 with all values=1 (pandas.DataFrame.insert function). This is for input to the bias $w_0$\n",
    "- Define X matrix (independent features) and y vector (target feature) as numpy arrays\n",
    "- Print the shape and datatype of both X and y\n",
    "[//]: # \"- Dataset contains missing values, hence fill the missing values (NA) by performing missing value prediction\"\n",
    "[//]: # \"- Since the all the features are in higher range, columns can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (sklearn.preprocessing.StandardScaler)\"\n",
    "- Split the dataset into 85% for training and rest 15% for testing (sklearn.model_selection.train_test_split function)\n",
    "- Follow logistic regression class and fill code where highlighted:\n",
    "    - Write sigmoid function to predict probabilities\n",
    "    - Write log likelihood function\n",
    "    - Write fit function where gradient ascent is implemented\n",
    "    - Write predict_proba function where we predict probabilities for input data\n",
    "- Train the model\n",
    "- Write function for calculating accuracy\n",
    "- Compute accuracy on train and test data\n",
    "\n",
    "#### Further Fun (will not be evaluated)\n",
    "- Play with learning rate and max_iterations\n",
    "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
    "- Train model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
    "- Shuffle training samples with different random seed values in the train_test_split function. Check the model error for the testing data for each setup.\n",
    "- Print other classification metrics such as:\n",
    "    - classification report (sklearn.metrics.classification_report),\n",
    "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
    "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
    "\n",
    "#### Helpful links\n",
    "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
    "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21J6cpd_wmSE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SL1fdNt1k3Q"
   },
   "outputs": [],
   "source": [
    "# Download the dataset from the source\n",
    "!wget _URL_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9av7W-wowmSI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  Atr10  ...  Atr46  \\\n",
       "0       2     2     4     1     0     0     0     0     0      0  ...      2   \n",
       "1       4     4     4     4     4     0     0     4     4      4  ...      2   \n",
       "2       2     2     2     2     1     3     2     1     1      2  ...      3   \n",
       "3       3     2     3     2     3     3     3     3     3      3  ...      2   \n",
       "4       2     2     1     1     1     1     0     0     0      0  ...      2   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...    ...   \n",
       "165     0     0     0     0     0     0     0     0     0      0  ...      1   \n",
       "166     0     0     0     0     0     0     0     0     0      0  ...      4   \n",
       "167     1     1     0     0     0     0     0     0     0      1  ...      3   \n",
       "168     0     0     0     0     0     0     0     0     0      0  ...      3   \n",
       "169     0     0     0     0     0     0     0     1     0      0  ...      3   \n",
       "\n",
       "     Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0        1      3      3      3      2      3      2      1      1  \n",
       "1        2      3      4      4      4      4      2      2      1  \n",
       "2        2      3      1      1      1      2      2      2      1  \n",
       "3        2      3      3      3      3      2      2      2      1  \n",
       "4        1      2      3      2      2      2      1      0      1  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "165      0      4      1      1      4      2      2      2      0  \n",
       "166      1      2      2      2      2      3      2      2      0  \n",
       "167      0      2      0      1      1      3      0      0      0  \n",
       "168      3      2      2      3      2      4      3      1      0  \n",
       "169      4      4      0      1      3      3      3      1      0  \n",
       "\n",
       "[170 rows x 55 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from local cloud directory\n",
    "data = pd.read_csv('data/divorce.csv', delimiter=';'  , engine='python') \n",
    "data\n",
    "# Set delimiter to semicolon(;) in case of unexpected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_0  Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  ...  Atr46  \\\n",
       "0      1     2     2     4     1     0     0     0     0     0  ...      2   \n",
       "1      1     4     4     4     4     4     0     0     4     4  ...      2   \n",
       "2      1     2     2     2     2     1     3     2     1     1  ...      3   \n",
       "3      1     3     2     3     2     3     3     3     3     3  ...      2   \n",
       "4      1     2     2     1     1     1     1     0     0     0  ...      2   \n",
       "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "165    1     0     0     0     0     0     0     0     0     0  ...      1   \n",
       "166    1     0     0     0     0     0     0     0     0     0  ...      4   \n",
       "167    1     1     1     0     0     0     0     0     0     0  ...      3   \n",
       "168    1     0     0     0     0     0     0     0     0     0  ...      3   \n",
       "169    1     0     0     0     0     0     0     0     1     0  ...      3   \n",
       "\n",
       "     Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0        1      3      3      3      2      3      2      1      1  \n",
       "1        2      3      4      4      4      4      2      2      1  \n",
       "2        2      3      1      1      1      2      2      2      1  \n",
       "3        2      3      3      3      3      2      2      2      1  \n",
       "4        1      2      3      2      2      2      1      0      1  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "165      0      4      1      1      4      2      2      2      0  \n",
       "166      1      2      2      2      2      3      2      2      0  \n",
       "167      0      2      0      1      1      3      0      0      0  \n",
       "168      3      2      2      3      2      4      3      1      0  \n",
       "169      4      4      0      1      3      3      3      1      0  \n",
       "\n",
       "[170 rows x 56 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column which has all 1s\n",
    "# The idea is that weight corresponding to this column is equal to intercept\n",
    "# This way it is efficient and easier to handle the bias/intercept term\n",
    "data.insert(0,'x_0',[1] * data.shape[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eV1jGAQxwmSP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_0  Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  ...  Atr46  \\\n",
       "0    1     2     2     4     1     0     0     0     0     0  ...      2   \n",
       "1    1     4     4     4     4     4     0     0     4     4  ...      2   \n",
       "2    1     2     2     2     2     1     3     2     1     1  ...      3   \n",
       "3    1     3     2     3     2     3     3     3     3     3  ...      2   \n",
       "4    1     2     2     1     1     1     1     0     0     0  ...      2   \n",
       "\n",
       "   Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0      1      3      3      3      2      3      2      1      1  \n",
       "1      2      3      4      4      4      4      2      2      1  \n",
       "2      2      3      1      1      1      2      2      2      1  \n",
       "3      2      3      3      3      3      2      2      2      1  \n",
       "4      1      2      3      2      2      2      1      0      1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dataframe rows just to see some samples\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joRU6dWxwmSR"
   },
   "outputs": [],
   "source": [
    "# Define X (input features) and y (output feature) \n",
    "X = data.iloc[:,0:55].values\n",
    "y = data['Class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAyM-CYCwmSU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)\n",
      "y: Type-<class 'numpy.ndarray'>, Shape-(170,)\n"
     ]
    }
   ],
   "source": [
    "X_shape = X.shape\n",
    "X_type  = type(X)\n",
    "y_shape = y.shape\n",
    "y_type  = type(y)\n",
    "print(f'X: Type-{X_type}, Shape-{X_shape}')\n",
    "print(f'y: Type-{y_type}, Shape-{y_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Expected output: </strong><br><br>\n",
    "\n",
    "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)<br>\n",
    "y: Type-<class 'numpy.ndarray'>, Shape-(170,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdLIVOm127-z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and fill any missing values if any\n",
    "is_missing_values = data.isnull()\n",
    "(is_missing_values.values == True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En9Kb9dh2-wm"
   },
   "outputs": [],
   "source": [
    "# Perform standarization (if required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8WF-EqO3BEa"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acCATJhI3FdH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (144, 55) , y_train: (144,)\n",
      "X_test: (26, 55) , y_test: (26,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of features and target of training and testing: X_train, X_test, y_train, y_test\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "X_test_shape  = X_test.shape\n",
    "y_test_shape  = y_test.shape\n",
    "\n",
    "print(f\"X_train: {X_train_shape} , y_train: {y_train_shape}\")\n",
    "print(f\"X_test: {X_test_shape} , y_test: {y_test_shape}\")\n",
    "assert (X_train.shape[0]==y_train.shape[0] and X_test.shape[0]==y_test.shape[0]), \"Check your splitting carefully\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSa7cW-NwmSd"
   },
   "source": [
    "##### Let us start implementing logistic regression from scratch. Just follow code cells, see hints if required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will build a LogisticRegression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT ANY VARIABLE OR FUNCTION NAME(S) IN THIS CELL\n",
    "# Let's try more object oriented approach this time :)\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, max_iterations=100):\n",
    "        '''Initialize variables\n",
    "        Args:\n",
    "            learning_rate  : Learning Rate\n",
    "            max_iterations : Max iterations for training weights\n",
    "        '''\n",
    "        # Initialising all the parameters\n",
    "        self.learning_rate  = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.likelihoods    = []\n",
    "        \n",
    "        # Define epsilon because log(0) is not defined\n",
    "        self.eps = 1e-7\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        '''Sigmoid function: f:R->(0,1)\n",
    "        Args:\n",
    "            z : A numpy array (num_samples,)\n",
    "        Returns:\n",
    "            A numpy array where sigmoid function applied to every element\n",
    "        '''\n",
    "        ### START CODE HERE\n",
    "        sig_z = 1/(1 + np.exp(-z))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
    "        return sig_z\n",
    "    \n",
    "    def log_likelihood(self, y_true, y_pred):\n",
    "        '''Calculates maximum likelihood estimate\n",
    "        Remember: y * log(yh) + (1-y) * log(1-yh)\n",
    "        Note: Likelihood is defined for multiple classes as well, but for this dataset\n",
    "        we only need to worry about binary/bernoulli likelihood function\n",
    "        Args:\n",
    "            y_true : Numpy array of actual truth values (num_samples,)\n",
    "            y_pred : Numpy array of predicted values (num_samples,)\n",
    "        Returns:\n",
    "            Log-likelihood, scalar value\n",
    "        '''\n",
    "        # Fix 0/1 values in y_pred so that log is not undefined\n",
    "        y_pred = np.maximum(np.full(y_pred.shape, self.eps), np.minimum(np.full(y_pred.shape, 1-self.eps), y_pred))\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        likelihood = (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return likelihood\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''Trains logistic regression model using gradient ascent\n",
    "        to gain maximum likelihood on the training data\n",
    "        Args:\n",
    "            X : Numpy array (num_examples, num_features)\n",
    "            y : Numpy array (num_examples, )\n",
    "        Returns: VOID\n",
    "        '''\n",
    "        \n",
    "        num_examples = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        \n",
    "        # Initialize weights with appropriate shape\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # Perform gradient ascent\n",
    "        for i in range(self.max_iterations):\n",
    "            # Define the linear hypothesis(z) first\n",
    "            # HINT: what is our hypothesis function in linear regression, remember?\n",
    "            z = np.dot(X,self.weights)\n",
    "            \n",
    "            # Output probability value by appplying sigmoid on z\n",
    "            y_pred = self.sigmoid(z)\n",
    "            \n",
    "            # Calculate the gradient values\n",
    "            # This is just vectorized efficient way of implementing gradient. Don't worry, we will discuss it later.\n",
    "            gradient = np.mean((y-y_pred)*X.T, axis=1)\n",
    "            \n",
    "            # Update the weights\n",
    "            # Caution: It is gradient ASCENT not descent\n",
    "            self.weights = self.weights + gradient\n",
    "            \n",
    "            # Calculating log likelihood\n",
    "            likelihood = self.log_likelihood(y,y_pred)\n",
    "\n",
    "            self.likelihoods.append(likelihood)\n",
    "    \n",
    "        ### END CODE HERE\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''Predict probabilities for given X.\n",
    "        Remember sigmoid returns value between 0 and 1.\n",
    "        Args:\n",
    "            X : Numpy array (num_samples, num_features)\n",
    "        Returns:\n",
    "            probabilities: Numpy array (num_samples,)\n",
    "        '''\n",
    "        if self.weights is None:\n",
    "            raise Exception(\"Fit the model before prediction\")\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        z = np.dot(X,self.weights)\n",
    "        probabilities = self.sigmoid(z)\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        '''Predict/Classify X in classes\n",
    "        Args:\n",
    "            X         : Numpy array (num_samples, num_features)\n",
    "            threshold : scalar value above which prediction is 1 else 0\n",
    "        Returns:\n",
    "            binary_predictions : Numpy array (num_samples,)\n",
    "        '''\n",
    "        # Thresholding probability to predict binary values\n",
    "#         binary_predictions = self.predict_proba(X).applymap(lambda x: 1 if x>threshold else 0)\n",
    "        binary_predictions = np.array(list(map(lambda x: 1 if x>threshold else 0, self.predict_proba(X))))\n",
    "        \n",
    "        return binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now initialize logitic regression implemented by you\n",
    "model = MyLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now fit on training data\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phew!! That's a lot of code. But you did it, congrats !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tvMc0OqwmSp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on training data: [-1.00000005e-07 -8.22850546e-05 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -1.56935553e-07 -6.11519763e-05\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.06681126e-02\n",
      " -1.80935228e-03 -1.73671704e-03 -2.04430384e-02 -4.85923126e-04\n",
      " -1.00000005e-07 -7.46935844e-02 -1.00000005e-07 -3.45242617e-04\n",
      " -1.00000005e-07 -1.00000005e-07 -2.47639838e-02 -1.00000005e-07\n",
      " -3.39152295e-04 -8.96549386e-02 -2.55502036e-04 -1.00000005e-07\n",
      " -1.00000005e-07 -2.25111456e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.01567492e-02 -1.00000005e-07 -1.00000005e-07\n",
      " -1.05704429e-01 -7.92952958e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -5.31875581e-05 -6.10744908e-06 -1.00000005e-07 -6.15628956e-05\n",
      " -4.44885085e-07 -1.59688662e-01 -2.47639838e-02 -1.18620479e-02\n",
      " -1.00000005e-07 -1.00000005e-07 -3.42765848e-04 -1.00000005e-07\n",
      " -1.00000005e-07 -2.04138499e-04 -1.00000005e-07 -1.00000005e-07\n",
      " -1.42614155e-05 -1.00000005e-07 -1.00000005e-07 -8.70831760e-02\n",
      " -1.00000005e-07 -2.12361840e-02 -1.48671842e-02 -1.13281030e-05\n",
      " -1.86947971e-05 -4.95840982e-04 -1.00000005e-07 -2.62604628e-02\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -5.97675142e-05\n",
      " -1.00000005e-07 -3.77834677e-06 -1.00000005e-07 -6.77421996e-05\n",
      " -7.52154464e-06 -6.01500910e-03 -1.00000005e-07 -8.67321145e-02\n",
      " -2.10115568e-05 -1.00000005e-07 -1.95147300e-03 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -2.34264477e-02 -3.97649686e-04 -4.70556988e-05 -1.00000005e-07\n",
      " -8.74778905e-05 -1.17849779e-02 -1.00300533e-01 -1.00000005e-07\n",
      " -2.06819137e-07 -2.36419716e-02 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -9.11086782e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -1.81589364e-04 -2.60250037e-06 -6.93850250e-02 -4.95867920e-03\n",
      " -1.00000005e-07 -1.00000005e-07 -3.21241551e-05 -1.00000005e-07\n",
      " -2.45675188e-02 -1.00000005e-07 -1.00000005e-07 -6.14573598e-02\n",
      " -1.00000005e-07 -1.00000005e-07 -1.60884802e-03 -1.21793603e-07\n",
      " -1.00000005e-07 -3.25898257e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -3.95534347e-02 -1.25496331e-03 -1.70394556e-04\n",
      " -8.40060252e-03 -2.66257709e-06 -1.95738723e-04 -1.00000005e-07\n",
      " -7.56270101e-03 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -2.80047663e-02 -3.04912712e-05]\n"
     ]
    }
   ],
   "source": [
    "# Train log-likelihood\n",
    "train_log_likelihood = model.log_likelihood(y_train, model.predict_proba(X_train))\n",
    "print(\"Log-likelihood on training data:\", train_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZQ8ITUt4b0N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on testing data: [-1.10061695e-04 -1.00000005e-07 -9.77611466e-05 -1.00000005e-07\n",
      " -6.08436821e-03 -1.94713223e-03 -4.07957319e-05 -1.00000005e-07\n",
      " -4.07695129e-03 -1.00000005e-07 -1.00000005e-07 -1.36468723e-02\n",
      " -8.51330641e-05 -1.00000005e-07 -1.00000005e-07 -2.32272363e-03\n",
      " -1.00000005e-07 -3.07116643e-06 -1.00000005e-07 -6.27217561e-04\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -5.87653097e-02]\n"
     ]
    }
   ],
   "source": [
    "# Test log-likelihood\n",
    "test_log_likelihood = model.log_likelihood(y_test, model.predict_proba(X_test))\n",
    "print(\"Log-likelihood on testing data:\", test_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot([i+1 for i in range(len(model.likelihoods))], model.likelihoods)\n",
    "plt.title(\"Log-Likelihood curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Log-likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's calculate accuracy as well. Accuracy is defined simply as the rate of correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    '''Compute accuracy.\n",
    "    Accuracy = (Correct prediction / number of samples)\n",
    "    Args:\n",
    "        y_true : Truth binary values (num_examples, )\n",
    "        y_pred : Predicted binary values (num_examples, )\n",
    "    Returns:\n",
    "        accuracy: scalar value\n",
    "    '''\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    accuracy = np.equal(y_true,y_pred).mean()\n",
    "#     print(accuracy)\n",
    "    ### END CODE HERE\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on train data\n",
    "y_pred = model.predict(X_train)\n",
    "print(accuracy(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on test data\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2: Use Logistic Regression from sklearn on the same dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "- Define X and y again for sklearn Linear Regression model\n",
    "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
    "- Run the model on testing set\n",
    "- Print 'accuracy' obtained on the testing dataset (sklearn.metrics.accuracy_score function)\n",
    "\n",
    "#### Further fun (will not be evaluated)\n",
    "- Compare accuracies of your model and sklearn's logistic regression model\n",
    "\n",
    "#### Helpful links\n",
    "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  Atr10  ...  Atr46  \\\n",
       "0       2     2     4     1     0     0     0     0     0      0  ...      2   \n",
       "1       4     4     4     4     4     0     0     4     4      4  ...      2   \n",
       "2       2     2     2     2     1     3     2     1     1      2  ...      3   \n",
       "3       3     2     3     2     3     3     3     3     3      3  ...      2   \n",
       "4       2     2     1     1     1     1     0     0     0      0  ...      2   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...    ...   \n",
       "165     0     0     0     0     0     0     0     0     0      0  ...      1   \n",
       "166     0     0     0     0     0     0     0     0     0      0  ...      4   \n",
       "167     1     1     0     0     0     0     0     0     0      1  ...      3   \n",
       "168     0     0     0     0     0     0     0     0     0      0  ...      3   \n",
       "169     0     0     0     0     0     0     0     1     0      0  ...      3   \n",
       "\n",
       "     Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0        1      3      3      3      2      3      2      1      1  \n",
       "1        2      3      4      4      4      4      2      2      1  \n",
       "2        2      3      1      1      1      2      2      2      1  \n",
       "3        2      3      3      3      3      2      2      2      1  \n",
       "4        1      2      3      2      2      2      1      0      1  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "165      0      4      1      1      4      2      2      2      0  \n",
       "166      1      2      2      2      2      3      2      2      0  \n",
       "167      0      2      0      1      1      3      0      0      0  \n",
       "168      3      2      2      3      2      4      3      1      0  \n",
       "169      4      4      0      1      3      3      3      1      0  \n",
       "\n",
       "[170 rows x 55 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/divorce.csv', delimiter=';'  , engine='python') \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = data.iloc[:,0:54].values\n",
    "y = data['Class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model from sklearn\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on testing set X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on testing set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy on testing set\n",
    "test_accuracy_sklearn = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nAccuracy on testing set: {test_accuracy_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task_1_logistic_divorse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
