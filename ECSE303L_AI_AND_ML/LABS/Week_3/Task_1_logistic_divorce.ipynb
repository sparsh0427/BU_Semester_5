{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMHjtVPbyaKP"
   },
   "source": [
    "## Logistic Regression Model for Divorce Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: Implement  linear regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJi26z8awmSD"
   },
   "source": [
    "### Logistic regression\n",
    "Logistic regression uses an equation as the representation, very much like linear regression.\n",
    "\n",
    "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
    "\n",
    "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at <strong>\"data/divorce.csv\"</strong> in the respective challenge's repo.<br>\n",
    "<strong>Original Source:</strong> https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set. Dataset is based on rating for questionnaire filled by people who already got divorse and those who is happily married.<br><br>\n",
    "\n",
    "[//]: # \"The dataset is available at http://archive.ics.uci.edu/ml/machine-learning-databases/00520/data.zip. Unzip the file and use either CSV or xlsx file.<br>\"\n",
    "\n",
    "\n",
    "#### Features (X)\n",
    "1. Atr1 - If one of us apologizes when our discussion deteriorates, the discussion ends. (Numeric | Range: 0-4)\n",
    "2. Atr2 - I know we can ignore our differences, even if things get hard sometimes. (Numeric | Range: 0-4)\n",
    "3. Atr3 - When we need it, we can take our discussions with my spouse from the beginning and correct it. (Numeric | Range: 0-4)\n",
    "4. Atr4 - When I discuss with my spouse, to contact him will eventually work. (Numeric | Range: 0-4)\n",
    "5. Atr5 - The time I spent with my wife is special for us. (Numeric | Range: 0-4)\n",
    "6. Atr6 - We don't have time at home as partners. (Numeric | Range: 0-4)\n",
    "7. Atr7 - We are like two strangers who share the same environment at home rather than family. (Numeric | Range: 0-4)\n",
    "\n",
    "&emsp;.<br>\n",
    "&emsp;.<br>\n",
    "&emsp;.<br>\n",
    "<br>\n",
    "54. Atr54 - I'm not afraid to tell my spouse about her/his incompetence. (Numeric | Range: 0-4)\n",
    "<br><br>\n",
    "Take a look above at the source of the original dataset for more details.\n",
    "\n",
    "#### Target (y)\n",
    "55. Class: (Binary | 1 => Divorced, 0 => Not divorced yet)\n",
    "\n",
    "#### Objective\n",
    "To gain understanding of logistic regression through implementing the model from scratch\n",
    "\n",
    "#### Tasks\n",
    "- Download and load the data (csv file contains ';' as delimiter)\n",
    "- Add column at position 0 with all values=1 (pandas.DataFrame.insert function). This is for input to the bias $w_0$\n",
    "- Define X matrix (independent features) and y vector (target feature) as numpy arrays\n",
    "- Print the shape and datatype of both X and y\n",
    "[//]: # \"- Dataset contains missing values, hence fill the missing values (NA) by performing missing value prediction\"\n",
    "[//]: # \"- Since the all the features are in higher range, columns can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (sklearn.preprocessing.StandardScaler)\"\n",
    "- Split the dataset into 85% for training and rest 15% for testing (sklearn.model_selection.train_test_split function)\n",
    "- Follow logistic regression class and fill code where highlighted:\n",
    "    - Write sigmoid function to predict probabilities\n",
    "    - Write log likelihood function\n",
    "    - Write fit function where gradient ascent is implemented\n",
    "    - Write predict_proba function where we predict probabilities for input data\n",
    "- Train the model\n",
    "- Write function for calculating accuracy\n",
    "- Compute accuracy on train and test data\n",
    "\n",
    "#### Further Fun (will not be evaluated)\n",
    "- Play with learning rate and max_iterations\n",
    "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
    "- Train model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
    "- Shuffle training samples with different random seed values in the train_test_split function. Check the model error for the testing data for each setup.\n",
    "- Print other classification metrics such as:\n",
    "    - classification report (sklearn.metrics.classification_report),\n",
    "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
    "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
    "\n",
    "#### Helpful links\n",
    "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
    "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21J6cpd_wmSE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SL1fdNt1k3Q"
   },
   "outputs": [],
   "source": [
    "# Download the dataset from the source\n",
    "!wget _URL_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9av7W-wowmSI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  Atr10  ...  Atr46  \\\n",
       "0       2     2     4     1     0     0     0     0     0      0  ...      2   \n",
       "1       4     4     4     4     4     0     0     4     4      4  ...      2   \n",
       "2       2     2     2     2     1     3     2     1     1      2  ...      3   \n",
       "3       3     2     3     2     3     3     3     3     3      3  ...      2   \n",
       "4       2     2     1     1     1     1     0     0     0      0  ...      2   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...    ...   \n",
       "165     0     0     0     0     0     0     0     0     0      0  ...      1   \n",
       "166     0     0     0     0     0     0     0     0     0      0  ...      4   \n",
       "167     1     1     0     0     0     0     0     0     0      1  ...      3   \n",
       "168     0     0     0     0     0     0     0     0     0      0  ...      3   \n",
       "169     0     0     0     0     0     0     0     1     0      0  ...      3   \n",
       "\n",
       "     Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0        1      3      3      3      2      3      2      1      1  \n",
       "1        2      3      4      4      4      4      2      2      1  \n",
       "2        2      3      1      1      1      2      2      2      1  \n",
       "3        2      3      3      3      3      2      2      2      1  \n",
       "4        1      2      3      2      2      2      1      0      1  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "165      0      4      1      1      4      2      2      2      0  \n",
       "166      1      2      2      2      2      3      2      2      0  \n",
       "167      0      2      0      1      1      3      0      0      0  \n",
       "168      3      2      2      3      2      4      3      1      0  \n",
       "169      4      4      0      1      3      3      3      1      0  \n",
       "\n",
       "[170 rows x 55 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from local cloud directory\n",
    "data = pd.read_csv('data/divorce.csv', delimiter=';'  , engine='python') \n",
    "data\n",
    "# Set delimiter to semicolon(;) in case of unexpected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_0  Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  ...  Atr46  \\\n",
       "0      1     2     2     4     1     0     0     0     0     0  ...      2   \n",
       "1      1     4     4     4     4     4     0     0     4     4  ...      2   \n",
       "2      1     2     2     2     2     1     3     2     1     1  ...      3   \n",
       "3      1     3     2     3     2     3     3     3     3     3  ...      2   \n",
       "4      1     2     2     1     1     1     1     0     0     0  ...      2   \n",
       "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "165    1     0     0     0     0     0     0     0     0     0  ...      1   \n",
       "166    1     0     0     0     0     0     0     0     0     0  ...      4   \n",
       "167    1     1     1     0     0     0     0     0     0     0  ...      3   \n",
       "168    1     0     0     0     0     0     0     0     0     0  ...      3   \n",
       "169    1     0     0     0     0     0     0     0     1     0  ...      3   \n",
       "\n",
       "     Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0        1      3      3      3      2      3      2      1      1  \n",
       "1        2      3      4      4      4      4      2      2      1  \n",
       "2        2      3      1      1      1      2      2      2      1  \n",
       "3        2      3      3      3      3      2      2      2      1  \n",
       "4        1      2      3      2      2      2      1      0      1  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "165      0      4      1      1      4      2      2      2      0  \n",
       "166      1      2      2      2      2      3      2      2      0  \n",
       "167      0      2      0      1      1      3      0      0      0  \n",
       "168      3      2      2      3      2      4      3      1      0  \n",
       "169      4      4      0      1      3      3      3      1      0  \n",
       "\n",
       "[170 rows x 56 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column which has all 1s\n",
    "# The idea is that weight corresponding to this column is equal to intercept\n",
    "# This way it is efficient and easier to handle the bias/intercept term\n",
    "data.insert(0,'x_0',[1] * data.shape[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eV1jGAQxwmSP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_0  Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  ...  Atr46  \\\n",
       "0    1     2     2     4     1     0     0     0     0     0  ...      2   \n",
       "1    1     4     4     4     4     4     0     0     4     4  ...      2   \n",
       "2    1     2     2     2     2     1     3     2     1     1  ...      3   \n",
       "3    1     3     2     3     2     3     3     3     3     3  ...      2   \n",
       "4    1     2     2     1     1     1     1     0     0     0  ...      2   \n",
       "\n",
       "   Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0      1      3      3      3      2      3      2      1      1  \n",
       "1      2      3      4      4      4      4      2      2      1  \n",
       "2      2      3      1      1      1      2      2      2      1  \n",
       "3      2      3      3      3      3      2      2      2      1  \n",
       "4      1      2      3      2      2      2      1      0      1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dataframe rows just to see some samples\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joRU6dWxwmSR"
   },
   "outputs": [],
   "source": [
    "# Define X (input features) and y (output feature) \n",
    "X = data.iloc[:,0:55].values\n",
    "y = data['Class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAyM-CYCwmSU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)\n",
      "y: Type-<class 'numpy.ndarray'>, Shape-(170,)\n"
     ]
    }
   ],
   "source": [
    "X_shape = X.shape\n",
    "X_type  = type(X)\n",
    "y_shape = y.shape\n",
    "y_type  = type(y)\n",
    "print(f'X: Type-{X_type}, Shape-{X_shape}')\n",
    "print(f'y: Type-{y_type}, Shape-{y_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Expected output: </strong><br><br>\n",
    "\n",
    "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)<br>\n",
    "y: Type-<class 'numpy.ndarray'>, Shape-(170,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdLIVOm127-z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and fill any missing values if any\n",
    "is_missing_values = data.isnull()\n",
    "(is_missing_values.values == True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En9Kb9dh2-wm"
   },
   "outputs": [],
   "source": [
    "# Perform standarization (if required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8WF-EqO3BEa"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acCATJhI3FdH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (144, 55) , y_train: (144,)\n",
      "X_test: (26, 55) , y_test: (26,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of features and target of training and testing: X_train, X_test, y_train, y_test\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "X_test_shape  = X_test.shape\n",
    "y_test_shape  = y_test.shape\n",
    "\n",
    "print(f\"X_train: {X_train_shape} , y_train: {y_train_shape}\")\n",
    "print(f\"X_test: {X_test_shape} , y_test: {y_test_shape}\")\n",
    "assert (X_train.shape[0]==y_train.shape[0] and X_test.shape[0]==y_test.shape[0]), \"Check your splitting carefully\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSa7cW-NwmSd"
   },
   "source": [
    "##### Let us start implementing logistic regression from scratch. Just follow code cells, see hints if required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will build a LogisticRegression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT ANY VARIABLE OR FUNCTION NAME(S) IN THIS CELL\n",
    "# Let's try more object oriented approach this time :)\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, max_iterations=1000):\n",
    "        '''Initialize variables\n",
    "        Args:\n",
    "            learning_rate  : Learning Rate\n",
    "            max_iterations : Max iterations for training weights\n",
    "        '''\n",
    "        # Initialising all the parameters\n",
    "        self.learning_rate  = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.likelihoods    = []\n",
    "        \n",
    "        # Define epsilon because log(0) is not defined\n",
    "        self.eps = 1e-7\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        '''Sigmoid function: f:R->(0,1)\n",
    "        Args:\n",
    "            z : A numpy array (num_samples,)\n",
    "        Returns:\n",
    "            A numpy array where sigmoid function applied to every element\n",
    "        '''\n",
    "        ### START CODE HERE\n",
    "        sig_z = 1/(1 + np.exp(-z))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
    "        return sig_z\n",
    "    \n",
    "    def log_likelihood(self, y_true, y_pred):\n",
    "        '''Calculates maximum likelihood estimate\n",
    "        Remember: y * log(yh) + (1-y) * log(1-yh)\n",
    "        Note: Likelihood is defined for multiple classes as well, but for this dataset\n",
    "        we only need to worry about binary/bernoulli likelihood function\n",
    "        Args:\n",
    "            y_true : Numpy array of actual truth values (num_samples,)\n",
    "            y_pred : Numpy array of predicted values (num_samples,)\n",
    "        Returns:\n",
    "            Log-likelihood, scalar value\n",
    "        '''\n",
    "        # Fix 0/1 values in y_pred so that log is not undefined\n",
    "        y_pred = np.maximum(np.full(y_pred.shape, self.eps), np.minimum(np.full(y_pred.shape, 1-self.eps), y_pred))\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        likelihood = (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return likelihood\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''Trains logistic regression model using gradient ascent\n",
    "        to gain maximum likelihood on the training data\n",
    "        Args:\n",
    "            X : Numpy array (num_examples, num_features)\n",
    "            y : Numpy array (num_examples, )\n",
    "        Returns: VOID\n",
    "        '''\n",
    "        \n",
    "        num_examples = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        \n",
    "        # Initialize weights with appropriate shape\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # Perform gradient ascent\n",
    "        for i in range(self.max_iterations):\n",
    "            # Define the linear hypothesis(z) first\n",
    "            # HINT: what is our hypothesis function in linear regression, remember?\n",
    "            z = np.dot(X,self.weights)\n",
    "            \n",
    "            # Output probability value by appplying sigmoid on z\n",
    "            y_pred = self.sigmoid(z)\n",
    "            \n",
    "            # Calculate the gradient values\n",
    "            # This is just vectorized efficient way of implementing gradient. Don't worry, we will discuss it later.\n",
    "            gradient = np.mean((y-y_pred)*X.T, axis=1)\n",
    "            \n",
    "            # Update the weights\n",
    "            # Caution: It is gradient ASCENT not descent\n",
    "            self.weights = self.weights + gradient\n",
    "            \n",
    "            # Calculating log likelihood\n",
    "            likelihood = self.log_likelihood(y,y_pred)\n",
    "\n",
    "            self.likelihoods.append(likelihood)\n",
    "    \n",
    "        ### END CODE HERE\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''Predict probabilities for given X.\n",
    "        Remember sigmoid returns value between 0 and 1.\n",
    "        Args:\n",
    "            X : Numpy array (num_samples, num_features)\n",
    "        Returns:\n",
    "            probabilities: Numpy array (num_samples,)\n",
    "        '''\n",
    "        if self.weights is None:\n",
    "            raise Exception(\"Fit the model before prediction\")\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        z = np.dot(X,self.weights)\n",
    "        probabilities = self.sigmoid(z)\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        '''Predict/Classify X in classes\n",
    "        Args:\n",
    "            X         : Numpy array (num_samples, num_features)\n",
    "            threshold : scalar value above which prediction is 1 else 0\n",
    "        Returns:\n",
    "            binary_predictions : Numpy array (num_samples,)\n",
    "        '''\n",
    "        # Thresholding probability to predict binary values\n",
    "#         binary_predictions = self.predict_proba(X).applymap(lambda x: 1 if x>threshold else 0)\n",
    "        binary_predictions = np.array(list(map(lambda x: 1 if x>threshold else 0, self.predict_proba(X))))\n",
    "        \n",
    "        return binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now initialize logitic regression implemented by you\n",
    "model = MyLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now fit on training data\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phew!! That's a lot of code. But you did it, congrats !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tvMc0OqwmSp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on training data: [-1.00000005e-07 -3.26339060e-05 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -4.73379076e-06\n",
      " -1.35758790e-07 -1.00000005e-07 -1.00000005e-07 -5.91216404e-04\n",
      " -3.08904974e-04 -1.18868740e-04 -6.98732746e-03 -3.36258734e-06\n",
      " -1.00000005e-07 -5.17451137e-03 -1.00000005e-07 -1.41398596e-05\n",
      " -1.00000005e-07 -1.00000005e-07 -1.71942783e-03 -1.00000005e-07\n",
      " -1.24205691e-04 -7.89175538e-03 -2.44366669e-06 -1.00000005e-07\n",
      " -1.00000005e-07 -3.26459198e-04 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -2.46439346e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -1.48461280e-02 -2.75423915e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -2.58690826e-05 -1.46494659e-07 -1.00000005e-07 -1.71826595e-05\n",
      " -1.00000005e-07 -1.68185656e-02 -1.71942783e-03 -1.72624951e-03\n",
      " -1.00000005e-07 -1.00000005e-07 -5.43037059e-05 -1.00000005e-07\n",
      " -1.00000005e-07 -8.07677523e-05 -1.00000005e-07 -1.00000005e-07\n",
      " -2.65038937e-06 -1.00000005e-07 -1.00000005e-07 -1.02081393e-02\n",
      " -1.00000005e-07 -4.35920834e-03 -1.81132141e-03 -1.56564169e-07\n",
      " -1.00000005e-07 -5.31494601e-05 -1.00000005e-07 -1.15177003e-03\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.29582065e-06\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -3.12594494e-05\n",
      " -1.75302288e-07 -1.64248406e-03 -1.00000005e-07 -1.22869856e-02\n",
      " -1.71265801e-06 -1.00000005e-07 -1.40038743e-04 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -5.59224766e-03 -7.23651132e-05 -7.59511282e-06 -1.00000005e-07\n",
      " -1.83191577e-05 -2.49640537e-03 -1.66924619e-02 -1.00000005e-07\n",
      " -1.00000005e-07 -2.85852112e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -3.72703409e-03 -1.00000005e-07 -1.00000005e-07\n",
      " -6.20236994e-06 -1.00000005e-07 -8.21391859e-03 -7.66994294e-04\n",
      " -1.00000005e-07 -1.00000005e-07 -1.07569782e-05 -1.00000005e-07\n",
      " -4.82705022e-03 -1.00000005e-07 -1.00000005e-07 -5.77175181e-03\n",
      " -1.00000005e-07 -1.00000005e-07 -1.08001782e-04 -1.00000005e-07\n",
      " -1.00000005e-07 -1.41305076e-04 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -5.61261416e-03 -1.39665865e-04 -4.11275749e-06\n",
      " -2.18780410e-03 -1.00000005e-07 -7.38155247e-06 -1.00000005e-07\n",
      " -2.69993263e-04 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -1.00000005e-07 -3.01219146e-03 -9.23929449e-07]\n"
     ]
    }
   ],
   "source": [
    "# Train log-likelihood\n",
    "train_log_likelihood = model.log_likelihood(y_train, model.predict_proba(X_train))\n",
    "print(\"Log-likelihood on training data:\", train_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZQ8ITUt4b0N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on testing data: [-2.88574892e-07 -1.00000005e-07 -5.93631193e-06 -1.00000005e-07\n",
      " -6.26781126e-04 -3.55214995e-05 -2.43115879e-06 -1.00000005e-07\n",
      " -5.60690677e-04 -1.00000005e-07 -1.00000005e-07 -1.39657833e-03\n",
      " -2.46392462e-05 -1.00000005e-07 -1.00000005e-07 -4.74950245e-04\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00217231e-04\n",
      " -1.00000005e-07 -1.00000005e-07 -1.00000005e-07 -1.00000005e-07\n",
      " -1.00000005e-07 -8.91675463e-03]\n"
     ]
    }
   ],
   "source": [
    "# Test log-likelihood\n",
    "test_log_likelihood = model.log_likelihood(y_test, model.predict_proba(X_test))\n",
    "print(\"Log-likelihood on testing data:\", test_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot([i+1 for i in range(len(model.likelihoods))], model.likelihoods)\n",
    "plt.title(\"Log-Likelihood curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Log-likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's calculate accuracy as well. Accuracy is defined simply as the rate of correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    '''Compute accuracy.\n",
    "    Accuracy = (Correct prediction / number of samples)\n",
    "    Args:\n",
    "        y_true : Truth binary values (num_examples, )\n",
    "        y_pred : Predicted binary values (num_examples, )\n",
    "    Returns:\n",
    "        accuracy: scalar value\n",
    "    '''\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    accuracy = np.equal(y_true,y_pred).mean()\n",
    "#     print(accuracy)\n",
    "    ### END CODE HERE\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on train data\n",
    "y_pred = model.predict(X_train)\n",
    "print(accuracy(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on test data\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2: Use Logistic Regression from sklearn on the same dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "- Define X and y again for sklearn Linear Regression model\n",
    "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
    "- Run the model on testing set\n",
    "- Print 'accuracy' obtained on the testing dataset (sklearn.metrics.accuracy_score function)\n",
    "\n",
    "#### Further fun (will not be evaluated)\n",
    "- Compare accuracies of your model and sklearn's logistic regression model\n",
    "\n",
    "#### Helpful links\n",
    "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  Atr10  ...  Atr46  \\\n",
       "0       2     2     4     1     0     0     0     0     0      0  ...      2   \n",
       "1       4     4     4     4     4     0     0     4     4      4  ...      2   \n",
       "2       2     2     2     2     1     3     2     1     1      2  ...      3   \n",
       "3       3     2     3     2     3     3     3     3     3      3  ...      2   \n",
       "4       2     2     1     1     1     1     0     0     0      0  ...      2   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...    ...   \n",
       "165     0     0     0     0     0     0     0     0     0      0  ...      1   \n",
       "166     0     0     0     0     0     0     0     0     0      0  ...      4   \n",
       "167     1     1     0     0     0     0     0     0     0      1  ...      3   \n",
       "168     0     0     0     0     0     0     0     0     0      0  ...      3   \n",
       "169     0     0     0     0     0     0     0     1     0      0  ...      3   \n",
       "\n",
       "     Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0        1      3      3      3      2      3      2      1      1  \n",
       "1        2      3      4      4      4      4      2      2      1  \n",
       "2        2      3      1      1      1      2      2      2      1  \n",
       "3        2      3      3      3      3      2      2      2      1  \n",
       "4        1      2      3      2      2      2      1      0      1  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "165      0      4      1      1      4      2      2      2      0  \n",
       "166      1      2      2      2      2      3      2      2      0  \n",
       "167      0      2      0      1      1      3      0      0      0  \n",
       "168      3      2      2      3      2      4      3      1      0  \n",
       "169      4      4      0      1      3      3      3      1      0  \n",
       "\n",
       "[170 rows x 55 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/divorce.csv', delimiter=';'  , engine='python') \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = data.iloc[:,0:54].values\n",
    "y = data['Class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model from sklearn\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on testing set X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on testing set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy on testing set\n",
    "test_accuracy_sklearn = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nAccuracy on testing set: {test_accuracy_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task_1_logistic_divorse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
