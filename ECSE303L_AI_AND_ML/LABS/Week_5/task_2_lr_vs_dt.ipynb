{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Customer response to Personal Loan Ad-Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "The dataset is available at <strong>\"data/personal_loan.csv\"</strong> in the respective challenge's repo.<br>\n",
    "Original Dataset : https://www.kaggle.com/itsmesunil/bank-loan-modelling\n",
    "\n",
    "#### Features (X)\n",
    "1. Age - Customer's age in completed years. (Numeric)\n",
    "2. Experience - No. of years of professional experience (Numeric)\n",
    "3. Income - Annual income of the customer. (Numeric)\n",
    "4. ZIPCode - Home Address ZIP code. (Numeric)\n",
    "5. Family - Family size of the customer. (Numeric)\n",
    "6. CCAvg Avg. - Spending on credit cards per month (Numeric)\n",
    "7. Education  - \n",
    "    - Education Level (Categorical|Multiclass):\n",
    "        - 1: Undergrad\n",
    "        - 2: Graduate\n",
    "        - 3: Advanced/Professional \n",
    "8. Mortgage - Value of house mortgage if any. (Numeric)\n",
    "9. Securities Account - Does the customer have a securities account with the bank? (Categorical | Binary)\n",
    "10. CD Account - Does the customer have a certificate of deposit (CD) account with the bank? (Categorical | Binary)\n",
    "11. Online - Does the customer use internet banking facilities? (Categorical | Binary)\n",
    "12. CreditCard - Does the customer uses a credit card issued by UniversalBank? (Categorical | Binary)\n",
    "\n",
    "#### Target (y)\n",
    "- Personal Loan : Did this customer accept the personal loan offered in the last campaign? (Binary)\n",
    "\n",
    "#### Objective\n",
    "- To apply Logistic Regression and Decision Tree Algorithms on the given imbalanced dataset. and compare the algorithms used on our dataset on the basis of appropriately used evaluated metrics while presenting a summarized analysis of what you find.\n",
    "\n",
    "#### Tasks\n",
    "- Download and load the data (csv file).\n",
    "- Process the data according to guidelines given in the comments of the respective cells.\n",
    "- Split the dataset into 80% for training and rest 20% for testing. (sklearn.model_selection.train_test_split function).\n",
    "- Initialize Logistic Regression and Decision Tree Models (With parameters given in the cell).\n",
    "- Train the models on the same dataset.\n",
    "- Compute the confusion matrix for both models and compare.\n",
    "- Compute a classification report (Precision, Recall and F-1 score) for both models and compare. \n",
    "- Compute and plot the ROC Curve of both curves and simultaneously compute the ROC-AUC for both models and thereby compare.\n",
    "- Summarize your findings and give reasoning for your results (comparing task_1 and task_2).\n",
    "\n",
    "#### Further Fun (will not be evaluated)\n",
    "- Train model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test.\n",
    "- Shuffle training samples with different random seed values in the train_test_split function. Check the model error for the testing data for each setup.\n",
    "- Explore ways to deal with imbalanced dataset. Use different methods (such as eliminating outliers and such) to experiment with the given dataset.\n",
    "\n",
    "#### Helpful links\n",
    "- pd.get_dummies() and One Hot Encoding: https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example\n",
    "- Differences between Logistic Regression and a Decision Tree: https://www.geeksforgeeks.org/ml-logistic-regression-v-s-decision-tree-classification/\n",
    "- When are Decision Trees better than Logistic Regression?: https://www.displayr.com/decision-trees-are-usually-better-than-logistic-regression\n",
    "- How to choose between Logistic Regression and Decision Trees given a dataset: https://datascience.stackexchange.com/questions/6048/should-i-use-a-decision-tree-or-logistic-regression-for-classification\n",
    "- Decision Tree Classifier by Sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- Understanding classification metrics like Precision, Recall, F-Scores and Confusion matrices: https://nillsf.com/index.php/2020/05/23/confusion-matrix-accuracy-recall-precision-false-positive-rate-and-f-scores-explained/\n",
    "- Understanding the ROC Curve: https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from the source\n",
    "!wget _URL_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from local cloud directory\n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataframe rows just to see some samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shape of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the distribution of target variable (Below is an example of what we mean)\n",
    "print(data['Personal Loan'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an imbalanced dataset, as shown above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print info about dataset\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing Values (if any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode Categorical Columns (if required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize/Standardize numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode columns with multiple categories\n",
    "# Use pd.get_dummies(), concatenate that with the original dataset, and drop the column (keeping only the dummy columns)\n",
    "# Use link given in the \"Helpful Links\" section for help\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Columns as X and Target Column as y\n",
    "X =\n",
    "y ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(?, ?, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "log_reg.fit(?,?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions on the test data (log_prob values represents raw probabilities of predictions)\n",
    "# It will be used for ROC Curves\n",
    "log_pred = log_reg.predict(?)\n",
    "log_prob = log_reg.predict_proba(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "d_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "d_tree.fit(?,?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions on the test data (dt_prob values represents raw probabilities of predictions)\n",
    "# It will be used for ROC Curves\n",
    "dt_pred = d_tree.predict(?)\n",
    "dt_prob = d_tree.predict_proba(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Our Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for Logistic Regression Model\n",
    "print(confusion_matrix(?,?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for Decision Tree Model\n",
    "print(confusion_matrix(?,?))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Think</b> : Would accuracy_score be a good evaluation metric, given that the dataset is imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the dataset is imbalanced, we evaluate our model using F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-Score for Logistic Regression Model\n",
    "print(f1_score(?,?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-Score for Decision Tree Model\n",
    "print(f1_score(?,?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for Logistic Regression Model\n",
    "print(classification_report(?,?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for Decision Tree Model\n",
    "print(classification_report(?,?))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ROC Curve and computing the ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC-AUC curve is a performance measurement for classification problems at various thresholds settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate False Positive Rate and True Positive Rate for y_test\n",
    "fpr1, tpr1, thresh1 = roc_curve(?, ?, pos_label=1)\n",
    "fpr2, tpr2, thresh2 = roc_curve(?, ?, pos_label=1)\n",
    "\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot ROC Curve (TPR vs FPR)\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
    "plt.plot(fpr2, tpr2, linestyle='-',color='green', label='Decision Tree')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='-.', color='blue')\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print ROC-AUC scores for both models\n",
    "auc_score1 = roc_auc_score(?, ?)\n",
    "auc_score2 = roc_auc_score(?, ?)\n",
    "\n",
    "print(\"ROC-AUC Score for Logistic Regression: \",auc_score1)\n",
    "print(\"ROC-AUC Score for Decision Tree: \",auc_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize your findings and give reasoning for the results you obtained from task_1 and task_2 and compare the algorithms utilized based on the evaluations metrics used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
