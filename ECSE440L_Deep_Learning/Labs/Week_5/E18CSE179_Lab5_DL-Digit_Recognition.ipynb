{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5_E18CSE227_DL (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "16GhsNNvy7o4",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thxn2N_rSyD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "715c9585-3c11-4724-bf60-94b19608eb3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OBCvqhLD4nHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9165727-b549-4f20-d11b-ab7da63daca4"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/digits\")\n",
        "files=os.listdir(\".\")\n",
        "print(files)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['digit_0', 'digit_1', 'digit_2', 'digit_3', 'digit_4', 'digit_5', 'digit_6', 'digit_7', 'digit_8', 'digit_9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AOMNETkS52C3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4f80b66a-26a6-41dd-8222-2741adb274c8"
      },
      "source": [
        "images=[]\n",
        "labels=[]\n",
        "for subdir in files:\n",
        "  os.chdir(\"/content/drive/My Drive/digits/{0}\".format(subdir))\n",
        "  temp=os.listdir(\".\")\n",
        "  for i in temp:\n",
        "    images.append(np.array(Image.open(i)).astype('float32'))\n",
        "    labels.append(subdir)\n",
        "print(len(images))\n",
        "print(len(labels))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1409\n",
            "1409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hp7ZZQxQGuPo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "31604e4e-eb45-4c7c-ce7e-448e40a5f8d1"
      },
      "source": [
        "print(images[27])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 5. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Apl8F4wCE0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d881ad3b-b034-4c9f-e1d1-1a88e8a0e2a9"
      },
      "source": [
        "images=np.array(images)\n",
        "labels=np.array(labels)\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1409, 32, 32)\n",
            "(1409,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "04R-QjGXCpAw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "23aa6484-7f3e-4585-83be-e475db06507b"
      },
      "source": [
        "plt.imshow(images[27],cmap='gray')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4b198e7b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KPASz_vLEjx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4ed4780f-71c2-4356-e555-6a650d075a07"
      },
      "source": [
        "# for i in range(images.shape[0]):\n",
        "#   images[i]=images[i]/255.0\n",
        "# print(images[2][-5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.14509805 0.6392157\n",
            " 0.972549   0.94509804 0.50980395 0.05490196 0.627451   0.9137255\n",
            " 0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFoGwnh1OcHT",
        "colab": {}
      },
      "source": [
        "LE=preprocessing.LabelEncoder()\n",
        "LE.fit(labels)\n",
        "labelsEnc=LE.transform(labels)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pKpIO_EWIpP6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "427407b5-4a1f-4bf7-a121-ec68c3641a50"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(images,labelsEnc,train_size=0.80,shuffle=True)\n",
        "print(\"Training set examples: \",X_train.shape[0] )\n",
        "print(\"Testing set examples: \",X_test.shape[0] )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set examples:  1127\n",
            "Testing set examples:  282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oUfCKMUuJfT_",
        "colab": {}
      },
      "source": [
        "model= tf.keras.models.Sequential(\n",
        "    [tf.keras.layers.Flatten(input_shape=(32,32)),\n",
        "    tf.keras.layers.Dense(32,activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')]\n",
        ")\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ot8GtF_sKcbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a2806047-6795-4b13-c5b8-2e9cac32599e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_12 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 32)                32800     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 33,130\n",
            "Trainable params: 33,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ec65MIFCKfkz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "589406b5-684e-4c00-a64a-9b45c985eeee"
      },
      "source": [
        "model.fit(x=X_train,y=y_train,epochs=100,validation_data=(X_test,y_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 36.4190 - accuracy: 0.6477 - val_loss: 1.4298 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.2970 - accuracy: 0.6176 - val_loss: 1.0581 - val_accuracy: 0.5922\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.9630 - accuracy: 0.6619 - val_loss: 0.8867 - val_accuracy: 0.6631\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8445 - accuracy: 0.6859 - val_loss: 0.9225 - val_accuracy: 0.6596\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7895 - accuracy: 0.6965 - val_loss: 0.8369 - val_accuracy: 0.6702\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7376 - accuracy: 0.7329 - val_loss: 0.9046 - val_accuracy: 0.7092\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.7498 - val_loss: 0.7692 - val_accuracy: 0.7234\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7326 - accuracy: 0.7737 - val_loss: 0.7742 - val_accuracy: 0.7589\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.7933 - val_loss: 1.1564 - val_accuracy: 0.7234\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.7941 - val_loss: 0.9197 - val_accuracy: 0.7553\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7890 - accuracy: 0.7649 - val_loss: 0.7537 - val_accuracy: 0.7305\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7478 - accuracy: 0.7595 - val_loss: 0.8658 - val_accuracy: 0.7411\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.7595 - val_loss: 0.7111 - val_accuracy: 0.7340\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.7649 - val_loss: 0.6561 - val_accuracy: 0.7411\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7737 - val_loss: 0.5880 - val_accuracy: 0.7589\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7835 - val_loss: 0.8811 - val_accuracy: 0.7589\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.7808 - val_loss: 0.5366 - val_accuracy: 0.7766\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.2483 - accuracy: 0.8021 - val_loss: 1.3831 - val_accuracy: 0.7411\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7755 - val_loss: 0.7694 - val_accuracy: 0.7305\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7755 - val_loss: 0.7335 - val_accuracy: 0.7376\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7870 - val_loss: 0.6857 - val_accuracy: 0.7411\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7968 - val_loss: 0.6267 - val_accuracy: 0.7660\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8039 - val_loss: 0.6040 - val_accuracy: 0.7730\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8066 - val_loss: 0.5788 - val_accuracy: 0.7766\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8083 - val_loss: 0.5810 - val_accuracy: 0.7766\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8092 - val_loss: 0.5771 - val_accuracy: 0.7801\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8092 - val_loss: 0.5761 - val_accuracy: 0.7801\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8092 - val_loss: 0.5760 - val_accuracy: 0.7801\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8092 - val_loss: 0.5762 - val_accuracy: 0.7801\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8092 - val_loss: 0.5766 - val_accuracy: 0.7801\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8092 - val_loss: 0.5763 - val_accuracy: 0.7801\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8092 - val_loss: 0.5766 - val_accuracy: 0.7801\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7941 - val_loss: 0.5763 - val_accuracy: 0.7943\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8075 - val_loss: 0.5775 - val_accuracy: 0.7801\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8092 - val_loss: 0.5782 - val_accuracy: 0.7801\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8092 - val_loss: 0.5782 - val_accuracy: 0.7801\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8092 - val_loss: 0.5784 - val_accuracy: 0.7801\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8092 - val_loss: 0.5785 - val_accuracy: 0.7801\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8092 - val_loss: 0.5795 - val_accuracy: 0.7801\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8092 - val_loss: 0.5794 - val_accuracy: 0.7801\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8092 - val_loss: 0.5810 - val_accuracy: 0.7801\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8092 - val_loss: 0.5809 - val_accuracy: 0.7801\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5805 - val_accuracy: 0.7801\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5813 - val_accuracy: 0.7801\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8092 - val_loss: 0.5817 - val_accuracy: 0.7801\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8092 - val_loss: 0.5824 - val_accuracy: 0.7801\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8092 - val_loss: 0.5828 - val_accuracy: 0.7801\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5834 - val_accuracy: 0.7801\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5833 - val_accuracy: 0.7801\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5834 - val_accuracy: 0.7801\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5839 - val_accuracy: 0.7801\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5835 - val_accuracy: 0.7801\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8092 - val_loss: 0.5844 - val_accuracy: 0.7801\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5851 - val_accuracy: 0.7801\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5856 - val_accuracy: 0.7801\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8092 - val_loss: 0.5851 - val_accuracy: 0.7801\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8092 - val_loss: 0.5856 - val_accuracy: 0.7801\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5855 - val_accuracy: 0.7801\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5856 - val_accuracy: 0.7801\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8092 - val_loss: 0.5866 - val_accuracy: 0.7801\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5863 - val_accuracy: 0.7801\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5867 - val_accuracy: 0.7801\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8092 - val_loss: 0.5881 - val_accuracy: 0.7801\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5878 - val_accuracy: 0.7801\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8092 - val_loss: 0.5874 - val_accuracy: 0.7801\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5876 - val_accuracy: 0.7801\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8092 - val_loss: 0.5884 - val_accuracy: 0.7801\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5888 - val_accuracy: 0.7801\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8092 - val_loss: 0.5882 - val_accuracy: 0.7801\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5884 - val_accuracy: 0.7801\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5888 - val_accuracy: 0.7801\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8092 - val_loss: 0.5886 - val_accuracy: 0.7801\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8092 - val_loss: 0.5894 - val_accuracy: 0.7801\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5902 - val_accuracy: 0.7801\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5908 - val_accuracy: 0.7801\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5910 - val_accuracy: 0.7801\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5912 - val_accuracy: 0.7801\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8092 - val_loss: 0.5920 - val_accuracy: 0.7801\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5920 - val_accuracy: 0.7801\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5923 - val_accuracy: 0.7801\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5913 - val_accuracy: 0.7801\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8012 - val_loss: 0.5915 - val_accuracy: 0.7801\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5923 - val_accuracy: 0.7801\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5925 - val_accuracy: 0.7801\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8092 - val_loss: 0.5929 - val_accuracy: 0.7801\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8092 - val_loss: 0.5925 - val_accuracy: 0.7801\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5931 - val_accuracy: 0.7801\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8092 - val_loss: 0.5936 - val_accuracy: 0.7801\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.8092 - val_loss: 0.5935 - val_accuracy: 0.7801\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8092 - val_loss: 0.5944 - val_accuracy: 0.7801\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5944 - val_accuracy: 0.7801\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8092 - val_loss: 0.5942 - val_accuracy: 0.7801\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8092 - val_loss: 0.5949 - val_accuracy: 0.7801\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8092 - val_loss: 0.5945 - val_accuracy: 0.7801\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8092 - val_loss: 0.5956 - val_accuracy: 0.7801\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5953 - val_accuracy: 0.7801\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8092 - val_loss: 0.5951 - val_accuracy: 0.7801\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8092 - val_loss: 0.5956 - val_accuracy: 0.7801\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5955 - val_accuracy: 0.7801\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8092 - val_loss: 0.5965 - val_accuracy: 0.7801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4b06e8ad30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mFDs9srCQ029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "63e77083-396b-401a-b72a-b9c42964c67d"
      },
      "source": [
        "trainLoss,trainAcc=model.evaluate(X_train,y_train,verbose=0)\n",
        "testLoss,testAcc=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(\"Training accuracy:\", trainAcc)\n",
        "print(\"Training Loss: \",trainLoss)\n",
        "print(\"Testing Accuracy:\" ,testAcc)\n",
        "print(\"Testing loss: \",testLoss)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.8092280626296997\n",
            "Training Loss:  0.4541401267051697\n",
            "Testing Accuracy: 0.7801418304443359\n",
            "Testing loss:  0.5965157747268677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EIHCb0gd0Dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b0cea8d-f6c2-4970-e6bd-123c1be3a8cf"
      },
      "source": [
        "nodes=[10,16,32,64,128,256,512,1024]\n",
        "times=[]\n",
        "trainAcc=[]\n",
        "testAcc=[]\n",
        "for i in nodes:\n",
        "  print(\"Nodes: \",i)\n",
        "  model= tf.keras.models.Sequential(\n",
        "    [tf.keras.layers.Flatten(input_shape=(32,32)),\n",
        "     tf.keras.layers.Dense(i,activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')]\n",
        "  )\n",
        "  model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "  init=time.time()\n",
        "  model.fit(x=X_train,y=y_train,epochs=100,validation_data=(X_test,y_test))\n",
        "  times.append(time.time()-init)\n",
        "  loss,Acc=model.evaluate(X_train,y_train,verbose=0)\n",
        "  trainAcc.append(Acc)\n",
        "  loss,Acc=model.evaluate(X_test,y_test,verbose=0)\n",
        "  testAcc.append(Acc)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nodes:  10\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 14.0166 - accuracy: 0.4179 - val_loss: 2.1374 - val_accuracy: 0.4752\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0669 - accuracy: 0.4720 - val_loss: 2.0032 - val_accuracy: 0.4752\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9550 - accuracy: 0.4720 - val_loss: 1.9154 - val_accuracy: 0.4752\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8897 - accuracy: 0.4720 - val_loss: 1.8766 - val_accuracy: 0.4752\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8603 - accuracy: 0.4720 - val_loss: 1.8560 - val_accuracy: 0.4752\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8485 - accuracy: 0.4720 - val_loss: 1.8503 - val_accuracy: 0.4752\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8446 - accuracy: 0.4720 - val_loss: 1.8486 - val_accuracy: 0.4752\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8437 - accuracy: 0.4720 - val_loss: 1.8483 - val_accuracy: 0.4752\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8433 - accuracy: 0.4720 - val_loss: 1.8483 - val_accuracy: 0.4752\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8474 - val_accuracy: 0.4752\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8429 - accuracy: 0.4720 - val_loss: 1.8471 - val_accuracy: 0.4752\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8472 - val_accuracy: 0.4752\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8421 - accuracy: 0.4720 - val_loss: 1.8495 - val_accuracy: 0.4752\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8487 - val_accuracy: 0.4752\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8489 - val_accuracy: 0.4752\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8420 - accuracy: 0.4720 - val_loss: 1.8486 - val_accuracy: 0.4752\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8479 - val_accuracy: 0.4752\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8486 - val_accuracy: 0.4752\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8479 - val_accuracy: 0.4752\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8473 - val_accuracy: 0.4752\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8479 - val_accuracy: 0.4752\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8472 - val_accuracy: 0.4752\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8461 - val_accuracy: 0.4752\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8484 - val_accuracy: 0.4752\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8420 - accuracy: 0.4720 - val_loss: 1.8480 - val_accuracy: 0.4752\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8477 - val_accuracy: 0.4752\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8465 - val_accuracy: 0.4752\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8455 - val_accuracy: 0.4752\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8423 - accuracy: 0.4720 - val_loss: 1.8468 - val_accuracy: 0.4752\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8420 - accuracy: 0.4720 - val_loss: 1.8476 - val_accuracy: 0.4752\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8473 - val_accuracy: 0.4752\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8467 - val_accuracy: 0.4752\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8422 - accuracy: 0.4720 - val_loss: 1.8472 - val_accuracy: 0.4752\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8466 - val_accuracy: 0.4752\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8474 - val_accuracy: 0.4752\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8467 - val_accuracy: 0.4752\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8422 - accuracy: 0.4720 - val_loss: 1.8462 - val_accuracy: 0.4752\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8423 - accuracy: 0.4720 - val_loss: 1.8463 - val_accuracy: 0.4752\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8466 - val_accuracy: 0.4752\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8469 - val_accuracy: 0.4752\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8475 - val_accuracy: 0.4752\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8430 - accuracy: 0.4720 - val_loss: 1.8482 - val_accuracy: 0.4752\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8479 - val_accuracy: 0.4752\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8421 - accuracy: 0.4720 - val_loss: 1.8471 - val_accuracy: 0.4752\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8484 - val_accuracy: 0.4752\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8467 - val_accuracy: 0.4752\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8466 - val_accuracy: 0.4752\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8455 - val_accuracy: 0.4752\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8420 - accuracy: 0.4720 - val_loss: 1.8474 - val_accuracy: 0.4752\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8478 - val_accuracy: 0.4752\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8469 - val_accuracy: 0.4752\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8471 - val_accuracy: 0.4752\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8467 - val_accuracy: 0.4752\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8475 - val_accuracy: 0.4752\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8464 - val_accuracy: 0.4752\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8465 - val_accuracy: 0.4752\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8422 - accuracy: 0.4720 - val_loss: 1.8478 - val_accuracy: 0.4752\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8422 - accuracy: 0.4720 - val_loss: 1.8486 - val_accuracy: 0.4752\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8476 - val_accuracy: 0.4752\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8473 - val_accuracy: 0.4752\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8458 - val_accuracy: 0.4752\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8480 - val_accuracy: 0.4752\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8430 - accuracy: 0.4720 - val_loss: 1.8465 - val_accuracy: 0.4752\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8482 - val_accuracy: 0.4752\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8476 - val_accuracy: 0.4752\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8423 - accuracy: 0.4720 - val_loss: 1.8481 - val_accuracy: 0.4752\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8477 - val_accuracy: 0.4752\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8422 - accuracy: 0.4720 - val_loss: 1.8472 - val_accuracy: 0.4752\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8472 - val_accuracy: 0.4752\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8432 - accuracy: 0.4720 - val_loss: 1.8483 - val_accuracy: 0.4752\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8422 - accuracy: 0.4720 - val_loss: 1.8482 - val_accuracy: 0.4752\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8429 - accuracy: 0.4720 - val_loss: 1.8474 - val_accuracy: 0.4752\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8478 - val_accuracy: 0.4752\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8423 - accuracy: 0.4720 - val_loss: 1.8482 - val_accuracy: 0.4752\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8429 - accuracy: 0.4720 - val_loss: 1.8481 - val_accuracy: 0.4752\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8432 - accuracy: 0.4720 - val_loss: 1.8482 - val_accuracy: 0.4752\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8487 - val_accuracy: 0.4752\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8487 - val_accuracy: 0.4752\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8438 - accuracy: 0.4720 - val_loss: 1.8476 - val_accuracy: 0.4752\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8432 - accuracy: 0.4720 - val_loss: 1.8480 - val_accuracy: 0.4752\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8482 - val_accuracy: 0.4752\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8421 - accuracy: 0.4720 - val_loss: 1.8491 - val_accuracy: 0.4752\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.4720 - val_loss: 1.8483 - val_accuracy: 0.4752\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8490 - val_accuracy: 0.4752\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4720 - val_loss: 1.8479 - val_accuracy: 0.4752\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8486 - val_accuracy: 0.4752\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8479 - val_accuracy: 0.4752\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8477 - val_accuracy: 0.4752\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8479 - val_accuracy: 0.4752\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8480 - val_accuracy: 0.4752\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.4720 - val_loss: 1.8475 - val_accuracy: 0.4752\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8478 - val_accuracy: 0.4752\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8423 - accuracy: 0.4720 - val_loss: 1.8475 - val_accuracy: 0.4752\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.4720 - val_loss: 1.8481 - val_accuracy: 0.4752\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8482 - val_accuracy: 0.4752\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8489 - val_accuracy: 0.4752\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8433 - accuracy: 0.4720 - val_loss: 1.8484 - val_accuracy: 0.4752\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8479 - val_accuracy: 0.4752\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8429 - accuracy: 0.4720 - val_loss: 1.8496 - val_accuracy: 0.4752\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.4720 - val_loss: 1.8484 - val_accuracy: 0.4752\n",
            "Nodes:  16\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 19.3581 - accuracy: 0.4286 - val_loss: 2.1246 - val_accuracy: 0.4858\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0395 - accuracy: 0.4889 - val_loss: 1.9968 - val_accuracy: 0.4823\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8856 - accuracy: 0.5040 - val_loss: 1.8343 - val_accuracy: 0.5071\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7552 - accuracy: 0.5297 - val_loss: 1.7780 - val_accuracy: 0.5071\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7092 - accuracy: 0.5244 - val_loss: 1.7282 - val_accuracy: 0.5142\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6865 - accuracy: 0.5271 - val_loss: 1.7407 - val_accuracy: 0.5071\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6739 - accuracy: 0.5271 - val_loss: 2.6375 - val_accuracy: 0.5213\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7099 - accuracy: 0.5297 - val_loss: 1.7507 - val_accuracy: 0.5035\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7436 - accuracy: 0.5067 - val_loss: 1.7520 - val_accuracy: 0.5035\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8202 - accuracy: 0.5191 - val_loss: 1.7269 - val_accuracy: 0.5106\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7655 - accuracy: 0.5084 - val_loss: 1.7281 - val_accuracy: 0.5106\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6673 - accuracy: 0.5297 - val_loss: 1.7283 - val_accuracy: 0.5106\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6632 - accuracy: 0.5288 - val_loss: 1.7273 - val_accuracy: 0.5106\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6621 - accuracy: 0.5288 - val_loss: 1.7266 - val_accuracy: 0.5106\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6615 - accuracy: 0.5288 - val_loss: 1.7267 - val_accuracy: 0.5106\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6612 - accuracy: 0.5288 - val_loss: 1.7262 - val_accuracy: 0.5106\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7268 - val_accuracy: 0.5106\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7277 - val_accuracy: 0.5106\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.5288 - val_loss: 1.7275 - val_accuracy: 0.5106\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6606 - accuracy: 0.5288 - val_loss: 1.7263 - val_accuracy: 0.5106\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6611 - accuracy: 0.5288 - val_loss: 1.7261 - val_accuracy: 0.5106\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7262 - val_accuracy: 0.5106\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6614 - accuracy: 0.5288 - val_loss: 1.7274 - val_accuracy: 0.5106\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6604 - accuracy: 0.5288 - val_loss: 1.7265 - val_accuracy: 0.5106\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6604 - accuracy: 0.5288 - val_loss: 1.7269 - val_accuracy: 0.5106\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7279 - val_accuracy: 0.5106\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6606 - accuracy: 0.5288 - val_loss: 1.7268 - val_accuracy: 0.5106\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7281 - val_accuracy: 0.5106\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6606 - accuracy: 0.5288 - val_loss: 1.7272 - val_accuracy: 0.5106\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7274 - val_accuracy: 0.5106\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7266 - val_accuracy: 0.5106\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7270 - val_accuracy: 0.5106\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7267 - val_accuracy: 0.5106\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6604 - accuracy: 0.5288 - val_loss: 1.7262 - val_accuracy: 0.5106\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7259 - val_accuracy: 0.5106\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7263 - val_accuracy: 0.5106\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6606 - accuracy: 0.5288 - val_loss: 1.7262 - val_accuracy: 0.5106\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6612 - accuracy: 0.5288 - val_loss: 1.7268 - val_accuracy: 0.5106\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6606 - accuracy: 0.5288 - val_loss: 1.7271 - val_accuracy: 0.5106\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7281 - val_accuracy: 0.5106\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7272 - val_accuracy: 0.5106\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6605 - accuracy: 0.5288 - val_loss: 1.7273 - val_accuracy: 0.5106\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.5288 - val_loss: 1.7270 - val_accuracy: 0.5106\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6603 - accuracy: 0.5288 - val_loss: 1.7268 - val_accuracy: 0.5106\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6606 - accuracy: 0.5288 - val_loss: 1.7271 - val_accuracy: 0.5106\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7262 - val_accuracy: 0.5106\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7267 - val_accuracy: 0.5106\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7270 - val_accuracy: 0.5106\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6612 - accuracy: 0.5288 - val_loss: 1.7277 - val_accuracy: 0.5106\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6603 - accuracy: 0.5288 - val_loss: 1.7272 - val_accuracy: 0.5106\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.5288 - val_loss: 1.7266 - val_accuracy: 0.5106\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7272 - val_accuracy: 0.5106\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6612 - accuracy: 0.5288 - val_loss: 1.7266 - val_accuracy: 0.5106\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7263 - val_accuracy: 0.5106\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7269 - val_accuracy: 0.5106\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7269 - val_accuracy: 0.5106\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6604 - accuracy: 0.5288 - val_loss: 1.7275 - val_accuracy: 0.5106\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6611 - accuracy: 0.5288 - val_loss: 1.7266 - val_accuracy: 0.5106\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7272 - val_accuracy: 0.5106\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7264 - val_accuracy: 0.5106\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7270 - val_accuracy: 0.5106\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6611 - accuracy: 0.5288 - val_loss: 1.7268 - val_accuracy: 0.5106\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7270 - val_accuracy: 0.5106\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7274 - val_accuracy: 0.5106\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6611 - accuracy: 0.5288 - val_loss: 1.7271 - val_accuracy: 0.5106\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7273 - val_accuracy: 0.5106\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6619 - accuracy: 0.5288 - val_loss: 1.7263 - val_accuracy: 0.5106\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6605 - accuracy: 0.5288 - val_loss: 1.7279 - val_accuracy: 0.5106\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7266 - val_accuracy: 0.5106\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.5288 - val_loss: 1.7276 - val_accuracy: 0.5106\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7275 - val_accuracy: 0.5106\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7284 - val_accuracy: 0.5106\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7279 - val_accuracy: 0.5106\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7270 - val_accuracy: 0.5106\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7271 - val_accuracy: 0.5106\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6614 - accuracy: 0.5288 - val_loss: 1.7267 - val_accuracy: 0.5106\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6611 - accuracy: 0.5288 - val_loss: 1.7273 - val_accuracy: 0.5106\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7267 - val_accuracy: 0.5106\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7267 - val_accuracy: 0.5106\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7266 - val_accuracy: 0.5106\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6612 - accuracy: 0.5288 - val_loss: 1.7256 - val_accuracy: 0.5106\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7255 - val_accuracy: 0.5106\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7260 - val_accuracy: 0.5106\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7259 - val_accuracy: 0.5106\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6614 - accuracy: 0.5288 - val_loss: 1.7277 - val_accuracy: 0.5106\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7257 - val_accuracy: 0.5106\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6607 - accuracy: 0.5288 - val_loss: 1.7266 - val_accuracy: 0.5106\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.5288 - val_loss: 1.7268 - val_accuracy: 0.5106\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6617 - accuracy: 0.5288 - val_loss: 1.7272 - val_accuracy: 0.5106\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.5288 - val_loss: 1.7270 - val_accuracy: 0.5106\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6605 - accuracy: 0.5288 - val_loss: 1.7264 - val_accuracy: 0.5106\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - accuracy: 0.5288 - val_loss: 1.7276 - val_accuracy: 0.5106\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6616 - accuracy: 0.5288 - val_loss: 1.7264 - val_accuracy: 0.5106\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6617 - accuracy: 0.5288 - val_loss: 1.7263 - val_accuracy: 0.5106\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6618 - accuracy: 0.5288 - val_loss: 1.7286 - val_accuracy: 0.5106\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7275 - val_accuracy: 0.5106\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7266 - val_accuracy: 0.5106\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5288 - val_loss: 1.7279 - val_accuracy: 0.5106\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6605 - accuracy: 0.5288 - val_loss: 1.7269 - val_accuracy: 0.5106\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.5288 - val_loss: 1.7278 - val_accuracy: 0.5106\n",
            "Nodes:  32\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 52.7457 - accuracy: 0.7693 - val_loss: 7.8972 - val_accuracy: 0.9220\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 5.9728 - accuracy: 0.9361 - val_loss: 11.1956 - val_accuracy: 0.8794\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.5021 - accuracy: 0.9539 - val_loss: 5.6824 - val_accuracy: 0.9468\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5228 - accuracy: 0.9769 - val_loss: 5.5438 - val_accuracy: 0.9433\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.9840 - val_loss: 2.6228 - val_accuracy: 0.9645\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.9894 - val_loss: 4.4244 - val_accuracy: 0.9610\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9938 - val_loss: 5.2744 - val_accuracy: 0.9645\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9956 - val_loss: 4.5084 - val_accuracy: 0.9574\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.9876 - val_loss: 4.4010 - val_accuracy: 0.9610\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.9823 - val_loss: 4.5346 - val_accuracy: 0.9610\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4214 - accuracy: 0.9805 - val_loss: 5.3228 - val_accuracy: 0.9645\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0039 - accuracy: 0.9885 - val_loss: 8.1183 - val_accuracy: 0.9504\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.3277 - accuracy: 0.9814 - val_loss: 7.0675 - val_accuracy: 0.9397\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.3452 - accuracy: 0.9778 - val_loss: 4.7872 - val_accuracy: 0.9610\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.2912 - accuracy: 0.9840 - val_loss: 5.3130 - val_accuracy: 0.9504\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.9867 - val_loss: 7.3641 - val_accuracy: 0.9539\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5267 - accuracy: 0.9840 - val_loss: 7.5537 - val_accuracy: 0.9362\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.3355 - accuracy: 0.9760 - val_loss: 7.7620 - val_accuracy: 0.9397\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8504 - accuracy: 0.9769 - val_loss: 4.9882 - val_accuracy: 0.9681\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.8247 - accuracy: 0.9698 - val_loss: 6.4391 - val_accuracy: 0.9681\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.3236 - accuracy: 0.9743 - val_loss: 14.0403 - val_accuracy: 0.9504\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5565 - accuracy: 0.9787 - val_loss: 5.8437 - val_accuracy: 0.9716\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7658 - accuracy: 0.9920 - val_loss: 7.7425 - val_accuracy: 0.9752\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0542 - accuracy: 0.9849 - val_loss: 6.0681 - val_accuracy: 0.9681\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9947 - val_loss: 6.5372 - val_accuracy: 0.9681\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8760 - accuracy: 0.9876 - val_loss: 3.9797 - val_accuracy: 0.9787\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.9929 - val_loss: 13.5743 - val_accuracy: 0.9539\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.9894 - val_loss: 7.2692 - val_accuracy: 0.9716\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.9929 - val_loss: 6.6283 - val_accuracy: 0.9716\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8533 - accuracy: 0.9920 - val_loss: 9.2059 - val_accuracy: 0.9681\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.9938 - val_loss: 11.4317 - val_accuracy: 0.9504\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.3887 - accuracy: 0.9911 - val_loss: 5.8358 - val_accuracy: 0.9610\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9929 - val_loss: 5.5740 - val_accuracy: 0.9716\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9973 - val_loss: 7.1203 - val_accuracy: 0.9645\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.9911 - val_loss: 3.7297 - val_accuracy: 0.9787\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9956 - val_loss: 2.8796 - val_accuracy: 0.9787\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9973 - val_loss: 3.8119 - val_accuracy: 0.9716\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9947 - val_loss: 4.1200 - val_accuracy: 0.9894\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.9938 - val_loss: 4.3274 - val_accuracy: 0.9752\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9965 - val_loss: 5.9545 - val_accuracy: 0.9858\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9973 - val_loss: 3.9456 - val_accuracy: 0.9823\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7740 - accuracy: 0.9929 - val_loss: 7.2191 - val_accuracy: 0.9681\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.9947 - val_loss: 6.5982 - val_accuracy: 0.9716\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9973 - val_loss: 4.5877 - val_accuracy: 0.9716\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9982 - val_loss: 5.8167 - val_accuracy: 0.9716\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.9947 - val_loss: 10.6414 - val_accuracy: 0.9539\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0806 - accuracy: 0.9947 - val_loss: 7.9300 - val_accuracy: 0.9645\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2531 - accuracy: 0.9920 - val_loss: 9.5681 - val_accuracy: 0.9645\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.8734 - accuracy: 0.9778 - val_loss: 40.4410 - val_accuracy: 0.9255\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 10.1712 - accuracy: 0.9654 - val_loss: 8.1281 - val_accuracy: 0.9823\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.8839 - accuracy: 0.9867 - val_loss: 10.1950 - val_accuracy: 0.9574\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8364 - accuracy: 0.9929 - val_loss: 9.9508 - val_accuracy: 0.9645\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9938 - val_loss: 13.0982 - val_accuracy: 0.9539\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.9752 - accuracy: 0.9938 - val_loss: 8.1297 - val_accuracy: 0.9752\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0350 - accuracy: 0.9920 - val_loss: 22.6871 - val_accuracy: 0.9574\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1358 - accuracy: 0.9894 - val_loss: 8.6154 - val_accuracy: 0.9752\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0500 - accuracy: 0.9867 - val_loss: 10.8588 - val_accuracy: 0.9787\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1480 - accuracy: 0.9911 - val_loss: 13.6875 - val_accuracy: 0.9574\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7838 - accuracy: 0.9876 - val_loss: 13.7664 - val_accuracy: 0.9716\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0271 - accuracy: 0.9894 - val_loss: 16.1824 - val_accuracy: 0.9681\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.3540 - accuracy: 0.9885 - val_loss: 16.7150 - val_accuracy: 0.9787\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.9440 - accuracy: 0.9885 - val_loss: 10.0532 - val_accuracy: 0.9681\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7887 - accuracy: 0.9876 - val_loss: 14.4196 - val_accuracy: 0.9716\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.3986 - accuracy: 0.9911 - val_loss: 20.7579 - val_accuracy: 0.9681\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9956 - val_loss: 20.4016 - val_accuracy: 0.9681\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9965 - val_loss: 15.0950 - val_accuracy: 0.9716\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 14.1623 - val_accuracy: 0.9716\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 14.1409 - val_accuracy: 0.9716\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 14.1405 - val_accuracy: 0.9716\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 14.1406 - val_accuracy: 0.9716\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 14.1413 - val_accuracy: 0.9716\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 14.1414 - val_accuracy: 0.9716\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 14.1415 - val_accuracy: 0.9716\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 14.1416 - val_accuracy: 0.9716\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 14.1418 - val_accuracy: 0.9716\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 14.1418 - val_accuracy: 0.9716\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 14.1420 - val_accuracy: 0.9716\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 14.1421 - val_accuracy: 0.9716\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 14.1422 - val_accuracy: 0.9716\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 14.1423 - val_accuracy: 0.9716\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 14.1424 - val_accuracy: 0.9716\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 14.1425 - val_accuracy: 0.9716\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 14.1426 - val_accuracy: 0.9716\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 14.1428 - val_accuracy: 0.9716\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 14.1430 - val_accuracy: 0.9716\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 14.1431 - val_accuracy: 0.9716\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 14.1433 - val_accuracy: 0.9716\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 14.1433 - val_accuracy: 0.9716\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 14.1434 - val_accuracy: 0.9716\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 14.1436 - val_accuracy: 0.9716\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9965 - val_loss: 14.1437 - val_accuracy: 0.9716\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9965 - val_loss: 14.1437 - val_accuracy: 0.9716\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9965 - val_loss: 14.1439 - val_accuracy: 0.9716\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9965 - val_loss: 14.1441 - val_accuracy: 0.9716\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9965 - val_loss: 14.1441 - val_accuracy: 0.9716\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9965 - val_loss: 14.1443 - val_accuracy: 0.9716\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9965 - val_loss: 14.1443 - val_accuracy: 0.9716\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9965 - val_loss: 14.1448 - val_accuracy: 0.9716\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9965 - val_loss: 14.1448 - val_accuracy: 0.9716\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9965 - val_loss: 14.1449 - val_accuracy: 0.9716\n",
            "Nodes:  64\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 57.1859 - accuracy: 0.8199 - val_loss: 5.9035 - val_accuracy: 0.9362\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 5.9536 - accuracy: 0.9556 - val_loss: 4.8539 - val_accuracy: 0.9645\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.5404 - accuracy: 0.9778 - val_loss: 8.1507 - val_accuracy: 0.9468\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4283 - accuracy: 0.9796 - val_loss: 2.8486 - val_accuracy: 0.9787\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.9876 - val_loss: 4.0794 - val_accuracy: 0.9574\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.9885 - val_loss: 4.0366 - val_accuracy: 0.9681\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7732 - accuracy: 0.9849 - val_loss: 5.3226 - val_accuracy: 0.9610\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8051 - accuracy: 0.9840 - val_loss: 3.9224 - val_accuracy: 0.9752\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.9965 - val_loss: 3.7994 - val_accuracy: 0.9787\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9973 - val_loss: 3.9528 - val_accuracy: 0.9681\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9982 - val_loss: 6.7166 - val_accuracy: 0.9610\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.9973 - val_loss: 4.8733 - val_accuracy: 0.9752\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.9902 - val_loss: 9.2122 - val_accuracy: 0.9610\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4199 - accuracy: 0.9867 - val_loss: 12.2816 - val_accuracy: 0.9610\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.9920 - val_loss: 6.4453 - val_accuracy: 0.9645\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7598 - accuracy: 0.9894 - val_loss: 4.8011 - val_accuracy: 0.9787\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2632 - accuracy: 0.9796 - val_loss: 10.0169 - val_accuracy: 0.9397\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.4243 - accuracy: 0.9796 - val_loss: 7.9341 - val_accuracy: 0.9645\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.1517 - accuracy: 0.9894 - val_loss: 7.9785 - val_accuracy: 0.9752\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1402 - accuracy: 0.9911 - val_loss: 6.3470 - val_accuracy: 0.9752\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0940 - accuracy: 0.9849 - val_loss: 11.1086 - val_accuracy: 0.9539\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6293 - accuracy: 0.9929 - val_loss: 8.9415 - val_accuracy: 0.9574\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.9544 - accuracy: 0.9831 - val_loss: 16.8071 - val_accuracy: 0.9326\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 9.6454 - accuracy: 0.9601 - val_loss: 44.2929 - val_accuracy: 0.9397\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 6.1190 - accuracy: 0.9823 - val_loss: 21.0419 - val_accuracy: 0.9681\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.4524 - accuracy: 0.9867 - val_loss: 21.9341 - val_accuracy: 0.9504\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.6757 - accuracy: 0.9876 - val_loss: 10.9802 - val_accuracy: 0.9787\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9965 - val_loss: 13.7650 - val_accuracy: 0.9645\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1941 - accuracy: 0.9885 - val_loss: 9.7453 - val_accuracy: 0.9787\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.4489 - accuracy: 0.9929 - val_loss: 18.2777 - val_accuracy: 0.9716\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.9662 - accuracy: 0.9965 - val_loss: 7.6003 - val_accuracy: 0.9787\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9991 - val_loss: 9.1105 - val_accuracy: 0.9716\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9991 - val_loss: 10.7160 - val_accuracy: 0.9787\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9982 - val_loss: 6.4202 - val_accuracy: 0.9787\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9991 - val_loss: 4.4886 - val_accuracy: 0.9787\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2638 - val_accuracy: 0.9787\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2590 - val_accuracy: 0.9787\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2589 - val_accuracy: 0.9787\n",
            "Nodes:  128\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 90.7277 - accuracy: 0.7897 - val_loss: 9.6423 - val_accuracy: 0.9468\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 6.1663 - accuracy: 0.9663 - val_loss: 3.1558 - val_accuracy: 0.9787\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.7338 - accuracy: 0.9778 - val_loss: 2.1612 - val_accuracy: 0.9787\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.4417 - accuracy: 0.9823 - val_loss: 5.1896 - val_accuracy: 0.9645\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9982 - val_loss: 2.9742 - val_accuracy: 0.9823\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9982 - val_loss: 7.2927 - val_accuracy: 0.9645\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2176 - accuracy: 0.9973 - val_loss: 2.8027 - val_accuracy: 0.9823\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9991 - val_loss: 2.4329 - val_accuracy: 0.9752\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.9947 - val_loss: 4.0371 - val_accuracy: 0.9681\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9165 - accuracy: 0.9831 - val_loss: 6.1645 - val_accuracy: 0.9645\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 12.8010 - accuracy: 0.9583 - val_loss: 20.2488 - val_accuracy: 0.9539\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.7628 - accuracy: 0.9814 - val_loss: 5.7985 - val_accuracy: 0.9716\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 8.1635 - accuracy: 0.9725 - val_loss: 11.2775 - val_accuracy: 0.9610\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4.1057 - accuracy: 0.9814 - val_loss: 25.4354 - val_accuracy: 0.9504\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 5.2082 - accuracy: 0.9849 - val_loss: 15.4598 - val_accuracy: 0.9787\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4935 - accuracy: 0.9929 - val_loss: 23.2072 - val_accuracy: 0.9752\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.9965 - val_loss: 16.6876 - val_accuracy: 0.9681\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9982 - val_loss: 11.9062 - val_accuracy: 0.9752\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9973 - val_loss: 11.4343 - val_accuracy: 0.9752\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.8456 - accuracy: 0.9956 - val_loss: 11.3764 - val_accuracy: 0.9787\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.9991 - val_loss: 11.6495 - val_accuracy: 0.9787\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.9973 - val_loss: 14.3866 - val_accuracy: 0.9716\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.9973 - val_loss: 9.9025 - val_accuracy: 0.9787\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.9938 - val_loss: 14.2726 - val_accuracy: 0.9787\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3555 - accuracy: 0.9929 - val_loss: 14.7256 - val_accuracy: 0.9787\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1833 - accuracy: 0.9956 - val_loss: 8.5519 - val_accuracy: 0.9787\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.1188 - accuracy: 0.9956 - val_loss: 14.4854 - val_accuracy: 0.9823\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4.2718 - accuracy: 0.9956 - val_loss: 4.9662 - val_accuracy: 0.9823\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8542 - accuracy: 0.9920 - val_loss: 8.4223 - val_accuracy: 0.9752\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8895 - accuracy: 0.9911 - val_loss: 15.9581 - val_accuracy: 0.9752\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 6.3767 - accuracy: 0.9902 - val_loss: 13.3013 - val_accuracy: 0.9716\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 7.5465 - accuracy: 0.9814 - val_loss: 33.1529 - val_accuracy: 0.9468\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 12.3305 - accuracy: 0.9823 - val_loss: 9.2354 - val_accuracy: 0.9823\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.0006 - accuracy: 0.9938 - val_loss: 13.3966 - val_accuracy: 0.9752\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5058 - accuracy: 0.9956 - val_loss: 31.2854 - val_accuracy: 0.9681\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6460 - accuracy: 0.9938 - val_loss: 33.9440 - val_accuracy: 0.9610\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.4256 - accuracy: 0.9965 - val_loss: 28.0893 - val_accuracy: 0.9681\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9991 - val_loss: 26.9427 - val_accuracy: 0.9787\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0229 - val_accuracy: 0.9787\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.0248 - val_accuracy: 0.9787\n",
            "Nodes:  256\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 81.9141 - accuracy: 0.8447 - val_loss: 6.0905 - val_accuracy: 0.9610\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 10.1442 - accuracy: 0.9654 - val_loss: 24.6297 - val_accuracy: 0.9291\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 5.4772 - accuracy: 0.9814 - val_loss: 14.2419 - val_accuracy: 0.9645\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3.0021 - accuracy: 0.9823 - val_loss: 8.0067 - val_accuracy: 0.9610\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.9929 - val_loss: 11.7525 - val_accuracy: 0.9574\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.9238 - accuracy: 0.9894 - val_loss: 16.4341 - val_accuracy: 0.9610\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.5134 - accuracy: 0.9885 - val_loss: 5.1653 - val_accuracy: 0.9787\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.4952 - accuracy: 0.9894 - val_loss: 11.2011 - val_accuracy: 0.9645\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.7001 - accuracy: 0.9920 - val_loss: 12.8836 - val_accuracy: 0.9539\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.6873 - accuracy: 0.9911 - val_loss: 20.9532 - val_accuracy: 0.9468\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4.1971 - accuracy: 0.9849 - val_loss: 20.6621 - val_accuracy: 0.9397\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4.1127 - accuracy: 0.9849 - val_loss: 16.2261 - val_accuracy: 0.9610\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 19.7024 - accuracy: 0.9698 - val_loss: 41.0858 - val_accuracy: 0.9610\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 8.7298 - accuracy: 0.9894 - val_loss: 38.5355 - val_accuracy: 0.9681\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 6.8461 - accuracy: 0.9849 - val_loss: 81.7406 - val_accuracy: 0.9433\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 19.9264 - accuracy: 0.9787 - val_loss: 25.5711 - val_accuracy: 0.9752\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 11.7338 - accuracy: 0.9867 - val_loss: 19.9913 - val_accuracy: 0.9752\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 5.2210 - accuracy: 0.9920 - val_loss: 22.0761 - val_accuracy: 0.9787\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.7787 - accuracy: 0.9956 - val_loss: 38.6957 - val_accuracy: 0.9787\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.0858 - accuracy: 0.9965 - val_loss: 73.8699 - val_accuracy: 0.9468\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4.7090 - accuracy: 0.9920 - val_loss: 24.4182 - val_accuracy: 0.9787\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.3976 - accuracy: 0.9973 - val_loss: 32.8442 - val_accuracy: 0.9716\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.7566 - accuracy: 0.9982 - val_loss: 26.6685 - val_accuracy: 0.9823\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4.0749 - accuracy: 0.9947 - val_loss: 39.3581 - val_accuracy: 0.9787\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.7350 - accuracy: 0.9956 - val_loss: 32.3607 - val_accuracy: 0.9716\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4.9831 - accuracy: 0.9956 - val_loss: 56.5633 - val_accuracy: 0.9645\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 13.1760 - accuracy: 0.9894 - val_loss: 58.3831 - val_accuracy: 0.9681\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 5.2828 - accuracy: 0.9902 - val_loss: 38.8650 - val_accuracy: 0.9752\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3.1979 - accuracy: 0.9938 - val_loss: 94.7513 - val_accuracy: 0.9468\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.3334 - accuracy: 0.9973 - val_loss: 64.3767 - val_accuracy: 0.9574\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.9982 - val_loss: 60.7324 - val_accuracy: 0.9645\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5781 - accuracy: 0.9982 - val_loss: 66.6403 - val_accuracy: 0.9681\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4.6422 - accuracy: 0.9947 - val_loss: 50.0400 - val_accuracy: 0.9716\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.1582 - accuracy: 0.9973 - val_loss: 78.5350 - val_accuracy: 0.9752\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.7862 - accuracy: 0.9956 - val_loss: 39.2045 - val_accuracy: 0.9752\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9991 - val_loss: 43.5441 - val_accuracy: 0.9752\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9991 - val_loss: 38.5312 - val_accuracy: 0.9823\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 20.1752 - accuracy: 0.9929 - val_loss: 45.9248 - val_accuracy: 0.9752\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.4006 - accuracy: 0.9982 - val_loss: 35.6571 - val_accuracy: 0.9823\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4.3752 - accuracy: 0.9947 - val_loss: 40.0974 - val_accuracy: 0.9787\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4.2708 - accuracy: 0.9982 - val_loss: 50.3304 - val_accuracy: 0.9787\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.4648 - accuracy: 0.9965 - val_loss: 78.1246 - val_accuracy: 0.9645\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4.5083 - accuracy: 0.9973 - val_loss: 35.2923 - val_accuracy: 0.9787\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.9982 - val_loss: 34.1568 - val_accuracy: 0.9787\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.3177 - accuracy: 0.9973 - val_loss: 37.0398 - val_accuracy: 0.9752\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3.8908 - accuracy: 0.9973 - val_loss: 47.7948 - val_accuracy: 0.9716\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.0648 - val_accuracy: 0.9681\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4395 - val_accuracy: 0.9681\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4482 - val_accuracy: 0.9681\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 57.4483 - val_accuracy: 0.9681\n",
            "Nodes:  512\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 286.0400 - accuracy: 0.7657 - val_loss: 20.6327 - val_accuracy: 0.9220\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 10.4484 - accuracy: 0.9645 - val_loss: 9.7919 - val_accuracy: 0.9645\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0606 - accuracy: 0.9814 - val_loss: 6.1465 - val_accuracy: 0.9752\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.7547 - accuracy: 0.9973 - val_loss: 3.3667 - val_accuracy: 0.9787\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.2044 - accuracy: 0.9991 - val_loss: 2.9999 - val_accuracy: 0.9787\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1736 - accuracy: 0.9965 - val_loss: 4.1777 - val_accuracy: 0.9787\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.9973 - val_loss: 4.5270 - val_accuracy: 0.9752\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.8842 - accuracy: 0.9902 - val_loss: 3.8369 - val_accuracy: 0.9716\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.6957 - accuracy: 0.9894 - val_loss: 5.5565 - val_accuracy: 0.9610\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3.3194 - accuracy: 0.9849 - val_loss: 16.4406 - val_accuracy: 0.9362\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3.3994 - accuracy: 0.9787 - val_loss: 28.7020 - val_accuracy: 0.9220\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 5.7493 - accuracy: 0.9796 - val_loss: 6.6287 - val_accuracy: 0.9787\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.8068 - accuracy: 0.9902 - val_loss: 22.9996 - val_accuracy: 0.9716\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3.3666 - accuracy: 0.9885 - val_loss: 10.1355 - val_accuracy: 0.9787\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3.3512 - accuracy: 0.9911 - val_loss: 13.3853 - val_accuracy: 0.9681\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0664 - accuracy: 0.9920 - val_loss: 12.5785 - val_accuracy: 0.9752\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 4.6615 - accuracy: 0.9885 - val_loss: 22.3944 - val_accuracy: 0.9504\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.6335 - accuracy: 0.9929 - val_loss: 22.3653 - val_accuracy: 0.9504\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.6095 - accuracy: 0.9920 - val_loss: 15.9518 - val_accuracy: 0.9681\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3.3156 - accuracy: 0.9902 - val_loss: 17.4438 - val_accuracy: 0.9645\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 6.0783 - accuracy: 0.9849 - val_loss: 24.2009 - val_accuracy: 0.9645\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 6.6142 - accuracy: 0.9849 - val_loss: 12.8888 - val_accuracy: 0.9752\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 7.0127 - accuracy: 0.9876 - val_loss: 18.9252 - val_accuracy: 0.9823\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 5.7495 - accuracy: 0.9911 - val_loss: 49.0333 - val_accuracy: 0.9468\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 9.1490 - accuracy: 0.9911 - val_loss: 12.1567 - val_accuracy: 0.9787\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 5.0924 - accuracy: 0.9911 - val_loss: 19.4855 - val_accuracy: 0.9752\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2067 - accuracy: 0.9973 - val_loss: 28.7056 - val_accuracy: 0.9681\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.4089 - accuracy: 0.9982 - val_loss: 29.7929 - val_accuracy: 0.9716\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 1.4689 - accuracy: 0.9965 - val_loss: 22.7733 - val_accuracy: 0.9681\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1977 - accuracy: 0.9947 - val_loss: 18.9602 - val_accuracy: 0.9752\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.3401 - accuracy: 0.9991 - val_loss: 19.7687 - val_accuracy: 0.9716\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 3.0729 - accuracy: 0.9947 - val_loss: 74.5582 - val_accuracy: 0.9574\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 12.7571 - accuracy: 0.9867 - val_loss: 23.6173 - val_accuracy: 0.9823\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 15.9479 - accuracy: 0.9911 - val_loss: 44.5761 - val_accuracy: 0.9610\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 7.1357 - accuracy: 0.9929 - val_loss: 12.1830 - val_accuracy: 0.9823\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 6.6375 - accuracy: 0.9956 - val_loss: 13.9739 - val_accuracy: 0.9787\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 3.5894 - accuracy: 0.9938 - val_loss: 21.3783 - val_accuracy: 0.9787\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1576 - accuracy: 0.9956 - val_loss: 11.7276 - val_accuracy: 0.9929\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.8676 - accuracy: 0.9991 - val_loss: 40.9264 - val_accuracy: 0.9752\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2338 - accuracy: 0.9956 - val_loss: 21.1221 - val_accuracy: 0.9858\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3.7733 - accuracy: 0.9973 - val_loss: 50.3338 - val_accuracy: 0.9716\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 5.3682 - accuracy: 0.9965 - val_loss: 23.5775 - val_accuracy: 0.9752\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.8588 - accuracy: 0.9947 - val_loss: 39.5228 - val_accuracy: 0.9787\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 3.9852 - accuracy: 0.9973 - val_loss: 54.8284 - val_accuracy: 0.9645\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 4.1951 - accuracy: 0.9965 - val_loss: 47.4355 - val_accuracy: 0.9716\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.0214 - accuracy: 0.9982 - val_loss: 28.8616 - val_accuracy: 0.9787\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0071 - val_accuracy: 0.9716\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0469 - val_accuracy: 0.9716\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.0478 - val_accuracy: 0.9716\n",
            "Nodes:  1024\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 554.0432 - accuracy: 0.7631 - val_loss: 116.3474 - val_accuracy: 0.8972\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 26.9058 - accuracy: 0.9627 - val_loss: 13.6655 - val_accuracy: 0.9645\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 3.0156 - accuracy: 0.9894 - val_loss: 11.0769 - val_accuracy: 0.9645\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 3.7479 - accuracy: 0.9929 - val_loss: 40.7246 - val_accuracy: 0.9362\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 6.4450 - accuracy: 0.9840 - val_loss: 21.5222 - val_accuracy: 0.9645\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 1.3427 - accuracy: 0.9902 - val_loss: 12.5390 - val_accuracy: 0.9752\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.9625 - accuracy: 0.9965 - val_loss: 13.5972 - val_accuracy: 0.9752\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2109 - accuracy: 0.9991 - val_loss: 14.8229 - val_accuracy: 0.9752\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9323 - val_accuracy: 0.9752\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 14.9351 - val_accuracy: 0.9752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0uJ2hiMeSS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c656c95c-6098-46c4-9873-4c5af77d5823"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "nodes = ['10', '16', '32', '64', '128','256','512','1024']\n",
        "ax.bar(nodes,times)\n",
        "print(\"Training Times\")\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Times\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNQt3SIzgmQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "af577371-aaac-450c-a2d2-a53b095f0486"
      },
      "source": [
        "print(\"Train and test loss: \")\n",
        "data = [trainAcc,testAcc]\n",
        "X = np.arange(len(nodes))\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(X + 0.00, data[0], color = 'b', width = 0.25)\n",
        "ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)\n",
        "ax.legend(labels=['Train Accuracy','Test Accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train and test loss: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXi2_aujhn7P",
        "colab_type": "text"
      },
      "source": [
        "## So by looking at the graph we can say that for nodes 32 onwards the training and testing accuracy improves significantly as compared to when nodes are 10 or 16. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQt4Hbgogmv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c6b83d9-d5d1-426c-e9b3-47ca361fbb94"
      },
      "source": [
        "layers=[2,3,4,5]\n",
        "times=[]\n",
        "trainAcc=[]\n",
        "testAcc=[]\n",
        "for i in range(len(layers)):\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(32,32)))\n",
        "  for j in range(layers[i]-1):\n",
        "    model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "  model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "  init=time.time()\n",
        "  model.fit(x=X_train,y=y_train,epochs=100,validation_data=(X_test,y_test))\n",
        "  times.append(time.time()-init)\n",
        "  loss,Acc=model.evaluate(X_train,y_train,verbose=0)\n",
        "  trainAcc.append(Acc)\n",
        "  loss,Acc=model.evaluate(X_test,y_test,verbose=0)\n",
        "  testAcc.append(Acc)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 38.9636 - accuracy: 0.5626 - val_loss: 1.3999 - val_accuracy: 0.5426\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.2821 - accuracy: 0.5501 - val_loss: 1.2403 - val_accuracy: 0.5248\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1439 - accuracy: 0.5626 - val_loss: 1.2321 - val_accuracy: 0.5496\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0878 - accuracy: 0.5821 - val_loss: 1.1746 - val_accuracy: 0.5461\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0928 - accuracy: 0.5759 - val_loss: 1.1706 - val_accuracy: 0.5319\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0806 - accuracy: 0.5714 - val_loss: 1.1873 - val_accuracy: 0.5355\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0770 - accuracy: 0.5697 - val_loss: 1.2369 - val_accuracy: 0.5461\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1497 - accuracy: 0.5785 - val_loss: 1.2377 - val_accuracy: 0.5426\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1187 - accuracy: 0.5759 - val_loss: 1.4856 - val_accuracy: 0.5426\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1052 - accuracy: 0.5776 - val_loss: 1.1802 - val_accuracy: 0.5390\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0738 - accuracy: 0.5723 - val_loss: 1.1699 - val_accuracy: 0.5355\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0589 - accuracy: 0.5785 - val_loss: 1.1695 - val_accuracy: 0.5426\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0582 - accuracy: 0.5803 - val_loss: 1.1692 - val_accuracy: 0.5355\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0574 - accuracy: 0.5821 - val_loss: 1.1692 - val_accuracy: 0.5355\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0567 - accuracy: 0.5714 - val_loss: 1.1695 - val_accuracy: 0.5426\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0562 - accuracy: 0.5803 - val_loss: 1.1697 - val_accuracy: 0.5355\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0560 - accuracy: 0.5705 - val_loss: 1.1699 - val_accuracy: 0.5355\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0558 - accuracy: 0.5768 - val_loss: 1.1699 - val_accuracy: 0.5426\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0557 - accuracy: 0.5741 - val_loss: 1.1692 - val_accuracy: 0.5355\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0557 - accuracy: 0.5723 - val_loss: 1.1690 - val_accuracy: 0.5426\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0558 - accuracy: 0.5723 - val_loss: 1.1691 - val_accuracy: 0.5426\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0555 - accuracy: 0.5794 - val_loss: 1.1701 - val_accuracy: 0.5461\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5705 - val_loss: 1.1695 - val_accuracy: 0.5355\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0563 - accuracy: 0.5794 - val_loss: 1.1700 - val_accuracy: 0.5461\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0553 - accuracy: 0.5705 - val_loss: 1.1711 - val_accuracy: 0.5390\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0557 - accuracy: 0.5821 - val_loss: 1.1708 - val_accuracy: 0.5390\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5821 - val_loss: 1.1700 - val_accuracy: 0.5390\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5830 - val_loss: 1.1708 - val_accuracy: 0.5461\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0556 - accuracy: 0.5821 - val_loss: 1.1712 - val_accuracy: 0.5461\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5821 - val_loss: 1.1704 - val_accuracy: 0.5461\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5768 - val_loss: 1.1702 - val_accuracy: 0.5390\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5741 - val_loss: 1.1713 - val_accuracy: 0.5390\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5741 - val_loss: 1.1724 - val_accuracy: 0.5390\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0555 - accuracy: 0.5821 - val_loss: 1.1727 - val_accuracy: 0.5390\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5750 - val_loss: 1.1708 - val_accuracy: 0.5390\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5741 - val_loss: 1.1713 - val_accuracy: 0.5461\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5794 - val_loss: 1.1720 - val_accuracy: 0.5390\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0555 - accuracy: 0.5821 - val_loss: 1.1722 - val_accuracy: 0.5461\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5785 - val_loss: 1.1714 - val_accuracy: 0.5390\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5768 - val_loss: 1.1706 - val_accuracy: 0.5461\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5741 - val_loss: 1.1715 - val_accuracy: 0.5390\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5697 - val_loss: 1.1724 - val_accuracy: 0.5390\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5732 - val_loss: 1.1735 - val_accuracy: 0.5461\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5750 - val_loss: 1.1734 - val_accuracy: 0.5390\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5821 - val_loss: 1.1731 - val_accuracy: 0.5390\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5821 - val_loss: 1.1723 - val_accuracy: 0.5390\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5741 - val_loss: 1.1737 - val_accuracy: 0.5461\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5821 - val_loss: 1.1733 - val_accuracy: 0.5461\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0556 - accuracy: 0.5688 - val_loss: 1.1728 - val_accuracy: 0.5390\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5705 - val_loss: 1.1720 - val_accuracy: 0.5390\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5821 - val_loss: 1.1715 - val_accuracy: 0.5390\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0555 - accuracy: 0.5803 - val_loss: 1.1739 - val_accuracy: 0.5461\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5705 - val_loss: 1.1725 - val_accuracy: 0.5390\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5821 - val_loss: 1.1734 - val_accuracy: 0.5390\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5821 - val_loss: 1.1734 - val_accuracy: 0.5390\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0555 - accuracy: 0.5821 - val_loss: 1.1734 - val_accuracy: 0.5390\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5821 - val_loss: 1.1734 - val_accuracy: 0.5390\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0553 - accuracy: 0.5803 - val_loss: 1.1748 - val_accuracy: 0.5461\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0556 - accuracy: 0.5732 - val_loss: 1.1730 - val_accuracy: 0.5461\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5821 - val_loss: 1.1739 - val_accuracy: 0.5461\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0555 - accuracy: 0.5821 - val_loss: 1.1725 - val_accuracy: 0.5461\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5723 - val_loss: 1.1733 - val_accuracy: 0.5461\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0553 - accuracy: 0.5697 - val_loss: 1.1733 - val_accuracy: 0.5461\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5776 - val_loss: 1.1740 - val_accuracy: 0.5390\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0548 - accuracy: 0.5821 - val_loss: 1.1733 - val_accuracy: 0.5390\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0548 - accuracy: 0.5759 - val_loss: 1.1738 - val_accuracy: 0.5461\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0557 - accuracy: 0.5821 - val_loss: 1.1732 - val_accuracy: 0.5461\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5768 - val_loss: 1.1735 - val_accuracy: 0.5390\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5768 - val_loss: 1.1732 - val_accuracy: 0.5390\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5768 - val_loss: 1.1731 - val_accuracy: 0.5461\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5821 - val_loss: 1.1738 - val_accuracy: 0.5461\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5732 - val_loss: 1.1738 - val_accuracy: 0.5461\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5794 - val_loss: 1.1741 - val_accuracy: 0.5390\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5768 - val_loss: 1.1734 - val_accuracy: 0.5461\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5759 - val_loss: 1.1744 - val_accuracy: 0.5390\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5830 - val_loss: 1.1746 - val_accuracy: 0.5461\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0548 - accuracy: 0.5732 - val_loss: 1.1743 - val_accuracy: 0.5461\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5821 - val_loss: 1.1746 - val_accuracy: 0.5461\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5821 - val_loss: 1.1745 - val_accuracy: 0.5461\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0553 - accuracy: 0.5776 - val_loss: 1.1737 - val_accuracy: 0.5390\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5776 - val_loss: 1.1736 - val_accuracy: 0.5461\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5759 - val_loss: 1.1741 - val_accuracy: 0.5390\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5821 - val_loss: 1.1738 - val_accuracy: 0.5390\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5812 - val_loss: 1.1729 - val_accuracy: 0.5461\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5741 - val_loss: 1.1739 - val_accuracy: 0.5390\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5803 - val_loss: 1.1727 - val_accuracy: 0.5461\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5821 - val_loss: 1.1734 - val_accuracy: 0.5461\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0548 - accuracy: 0.5821 - val_loss: 1.1727 - val_accuracy: 0.5461\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5776 - val_loss: 1.1736 - val_accuracy: 0.5390\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5803 - val_loss: 1.1727 - val_accuracy: 0.5390\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5688 - val_loss: 1.1725 - val_accuracy: 0.5461\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5821 - val_loss: 1.1729 - val_accuracy: 0.5461\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0553 - accuracy: 0.5812 - val_loss: 1.1723 - val_accuracy: 0.5390\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5759 - val_loss: 1.1723 - val_accuracy: 0.5461\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5723 - val_loss: 1.1725 - val_accuracy: 0.5461\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5732 - val_loss: 1.1724 - val_accuracy: 0.5461\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0557 - accuracy: 0.5847 - val_loss: 1.1725 - val_accuracy: 0.5390\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0554 - accuracy: 0.5821 - val_loss: 1.1712 - val_accuracy: 0.5390\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.5821 - val_loss: 1.1727 - val_accuracy: 0.5390\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.5776 - val_loss: 1.1730 - val_accuracy: 0.5461\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 34.0023 - accuracy: 0.6930 - val_loss: 8.8428 - val_accuracy: 0.8511\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4.5614 - accuracy: 0.8962 - val_loss: 2.3428 - val_accuracy: 0.9184\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5516 - accuracy: 0.9388 - val_loss: 3.0118 - val_accuracy: 0.9397\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0812 - accuracy: 0.9485 - val_loss: 2.5063 - val_accuracy: 0.9468\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.9689 - val_loss: 2.4421 - val_accuracy: 0.9291\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1306 - accuracy: 0.9583 - val_loss: 3.0523 - val_accuracy: 0.9397\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1093 - accuracy: 0.9601 - val_loss: 3.3533 - val_accuracy: 0.9113\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1514 - accuracy: 0.9610 - val_loss: 2.9077 - val_accuracy: 0.9433\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0530 - accuracy: 0.9627 - val_loss: 3.3809 - val_accuracy: 0.9149\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8838 - accuracy: 0.9698 - val_loss: 1.9504 - val_accuracy: 0.9468\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.9787 - val_loss: 2.1932 - val_accuracy: 0.9610\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9849 - val_loss: 1.8872 - val_accuracy: 0.9433\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.9743 - val_loss: 2.1271 - val_accuracy: 0.9645\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.0161 - accuracy: 0.9734 - val_loss: 2.6978 - val_accuracy: 0.9574\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8912 - accuracy: 0.9734 - val_loss: 2.8851 - val_accuracy: 0.9504\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.9689 - val_loss: 4.5350 - val_accuracy: 0.9397\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4665 - accuracy: 0.9663 - val_loss: 5.1413 - val_accuracy: 0.9574\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0732 - accuracy: 0.9752 - val_loss: 3.6895 - val_accuracy: 0.9468\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0390 - accuracy: 0.9778 - val_loss: 5.1285 - val_accuracy: 0.9397\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.9814 - val_loss: 3.9966 - val_accuracy: 0.9610\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.9867 - val_loss: 2.4688 - val_accuracy: 0.9610\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9911 - val_loss: 2.7557 - val_accuracy: 0.9716\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.9831 - val_loss: 1.9823 - val_accuracy: 0.9574\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8532 - accuracy: 0.9858 - val_loss: 3.2535 - val_accuracy: 0.9645\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.3926 - accuracy: 0.9716 - val_loss: 6.0654 - val_accuracy: 0.9539\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.3069 - accuracy: 0.9796 - val_loss: 6.9029 - val_accuracy: 0.9291\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1419 - accuracy: 0.9645 - val_loss: 2.5317 - val_accuracy: 0.9220\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.9734 - val_loss: 1.5634 - val_accuracy: 0.9681\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.9805 - val_loss: 1.6463 - val_accuracy: 0.9574\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.9814 - val_loss: 2.0104 - val_accuracy: 0.9681\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9885 - val_loss: 1.5794 - val_accuracy: 0.9752\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9920 - val_loss: 2.0806 - val_accuracy: 0.9716\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9938 - val_loss: 2.0029 - val_accuracy: 0.9681\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 1.9310 - val_accuracy: 0.9716\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.9076 - val_accuracy: 0.9716\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9956 - val_loss: 1.8931 - val_accuracy: 0.9716\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9956 - val_loss: 1.8841 - val_accuracy: 0.9716\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9956 - val_loss: 1.8797 - val_accuracy: 0.9716\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 1.8775 - val_accuracy: 0.9716\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 1.8744 - val_accuracy: 0.9716\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.8720 - val_accuracy: 0.9716\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 1.8693 - val_accuracy: 0.9716\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.8671 - val_accuracy: 0.9716\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.8649 - val_accuracy: 0.9716\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 1.8632 - val_accuracy: 0.9716\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 1.8619 - val_accuracy: 0.9716\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 1.8610 - val_accuracy: 0.9716\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 1.8586 - val_accuracy: 0.9716\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 1.8574 - val_accuracy: 0.9716\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 1.8561 - val_accuracy: 0.9716\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 1.8548 - val_accuracy: 0.9716\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 1.8537 - val_accuracy: 0.9716\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 1.8525 - val_accuracy: 0.9716\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 1.8516 - val_accuracy: 0.9716\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 1.8505 - val_accuracy: 0.9716\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 1.8497 - val_accuracy: 0.9716\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9965 - val_loss: 1.8484 - val_accuracy: 0.9716\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9965 - val_loss: 1.8474 - val_accuracy: 0.9716\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9965 - val_loss: 1.8465 - val_accuracy: 0.9716\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9965 - val_loss: 1.8454 - val_accuracy: 0.9716\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9965 - val_loss: 1.8447 - val_accuracy: 0.9716\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9965 - val_loss: 1.8437 - val_accuracy: 0.9716\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9965 - val_loss: 1.8428 - val_accuracy: 0.9716\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9965 - val_loss: 1.8422 - val_accuracy: 0.9716\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9965 - val_loss: 1.8413 - val_accuracy: 0.9716\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9965 - val_loss: 1.8404 - val_accuracy: 0.9716\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9965 - val_loss: 1.8397 - val_accuracy: 0.9716\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9965 - val_loss: 1.8392 - val_accuracy: 0.9716\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9965 - val_loss: 1.8368 - val_accuracy: 0.9716\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9965 - val_loss: 1.8360 - val_accuracy: 0.9716\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9965 - val_loss: 1.8354 - val_accuracy: 0.9716\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9965 - val_loss: 1.8346 - val_accuracy: 0.9716\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9965 - val_loss: 1.8338 - val_accuracy: 0.9716\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9947 - val_loss: 1.8329 - val_accuracy: 0.9716\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9965 - val_loss: 1.8325 - val_accuracy: 0.9716\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9965 - val_loss: 1.8318 - val_accuracy: 0.9716\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9965 - val_loss: 1.8311 - val_accuracy: 0.9716\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9965 - val_loss: 1.8308 - val_accuracy: 0.9716\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9965 - val_loss: 1.8298 - val_accuracy: 0.9716\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9965 - val_loss: 1.8294 - val_accuracy: 0.9716\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9965 - val_loss: 1.8286 - val_accuracy: 0.9716\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9947 - val_loss: 1.8279 - val_accuracy: 0.9716\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9956 - val_loss: 1.8273 - val_accuracy: 0.9716\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9965 - val_loss: 1.8269 - val_accuracy: 0.9716\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9965 - val_loss: 1.8262 - val_accuracy: 0.9716\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9965 - val_loss: 1.8257 - val_accuracy: 0.9716\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9965 - val_loss: 1.8253 - val_accuracy: 0.9716\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9965 - val_loss: 1.8244 - val_accuracy: 0.9716\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9965 - val_loss: 1.8238 - val_accuracy: 0.9716\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 1.8234 - val_accuracy: 0.9716\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 1.8228 - val_accuracy: 0.9716\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 1.8221 - val_accuracy: 0.9716\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 1.8217 - val_accuracy: 0.9716\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9956 - val_loss: 1.8211 - val_accuracy: 0.9716\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 1.8208 - val_accuracy: 0.9716\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 1.8202 - val_accuracy: 0.9716\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9956 - val_loss: 1.8188 - val_accuracy: 0.9716\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 1.8183 - val_accuracy: 0.9716\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9947 - val_loss: 1.8179 - val_accuracy: 0.9716\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 1.8171 - val_accuracy: 0.9716\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 15.4550 - accuracy: 0.5519 - val_loss: 2.3026 - val_accuracy: 0.6206\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5709 - accuracy: 0.6522 - val_loss: 1.0304 - val_accuracy: 0.6241\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8558 - accuracy: 0.7240 - val_loss: 0.7694 - val_accuracy: 0.7589\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7693 - accuracy: 0.7498 - val_loss: 0.5447 - val_accuracy: 0.8156\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.8137 - val_loss: 0.6703 - val_accuracy: 0.7872\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8234 - val_loss: 0.4696 - val_accuracy: 0.8262\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.8367 - val_loss: 0.4264 - val_accuracy: 0.8511\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8722 - val_loss: 0.4497 - val_accuracy: 0.8794\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8971 - val_loss: 0.5930 - val_accuracy: 0.8298\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8625 - val_loss: 0.6227 - val_accuracy: 0.8546\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.8341 - val_loss: 1.1600 - val_accuracy: 0.8227\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0240 - accuracy: 0.7791 - val_loss: 0.7942 - val_accuracy: 0.8121\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.9406 - accuracy: 0.7471 - val_loss: 0.8533 - val_accuracy: 0.7553\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.8128 - val_loss: 0.7425 - val_accuracy: 0.7801\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.8412 - val_loss: 0.5883 - val_accuracy: 0.8298\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8385 - val_loss: 0.5653 - val_accuracy: 0.7837\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8447 - val_loss: 0.5272 - val_accuracy: 0.8191\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8687 - val_loss: 0.6226 - val_accuracy: 0.8333\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8642 - val_loss: 0.6205 - val_accuracy: 0.8262\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8696 - val_loss: 0.6602 - val_accuracy: 0.8156\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8669 - val_loss: 0.7095 - val_accuracy: 0.8227\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8687 - val_loss: 0.7725 - val_accuracy: 0.8014\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8598 - val_loss: 0.5146 - val_accuracy: 0.8227\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8580 - val_loss: 0.5303 - val_accuracy: 0.8262\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8589 - val_loss: 0.6372 - val_accuracy: 0.8333\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.8660 - val_loss: 0.6011 - val_accuracy: 0.8475\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8687 - val_loss: 0.5255 - val_accuracy: 0.8262\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.8713 - val_loss: 0.6066 - val_accuracy: 0.8262\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.8740 - val_loss: 0.5868 - val_accuracy: 0.8262\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.8793 - val_loss: 0.6704 - val_accuracy: 0.8369\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.8802 - val_loss: 0.5079 - val_accuracy: 0.8298\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.8784 - val_loss: 0.5387 - val_accuracy: 0.8333\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.8882 - val_loss: 0.5499 - val_accuracy: 0.8333\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.8935 - val_loss: 0.6138 - val_accuracy: 0.8298\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.8873 - val_loss: 0.4869 - val_accuracy: 0.8369\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.8722 - val_loss: 0.5270 - val_accuracy: 0.8369\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.8776 - val_loss: 0.5240 - val_accuracy: 0.8333\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.8855 - val_loss: 0.5973 - val_accuracy: 0.8440\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9015 - val_loss: 0.4840 - val_accuracy: 0.8475\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9042 - val_loss: 0.4572 - val_accuracy: 0.8546\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9068 - val_loss: 0.6767 - val_accuracy: 0.8298\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8669 - val_loss: 1.4723 - val_accuracy: 0.7766\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.8190 - val_loss: 0.9000 - val_accuracy: 0.8262\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.8146 - val_loss: 0.9702 - val_accuracy: 0.7270\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7165 - accuracy: 0.7631 - val_loss: 0.7788 - val_accuracy: 0.7553\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.9119 - accuracy: 0.7382 - val_loss: 1.5987 - val_accuracy: 0.5709\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7182 - accuracy: 0.5235 - val_loss: 1.1854 - val_accuracy: 0.7092\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.9011 - accuracy: 0.7107 - val_loss: 1.0843 - val_accuracy: 0.6809\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.8319 - accuracy: 0.7249 - val_loss: 0.9493 - val_accuracy: 0.7021\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1759 - accuracy: 0.6637 - val_loss: 1.2449 - val_accuracy: 0.6525\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1992 - accuracy: 0.6823 - val_loss: 1.2889 - val_accuracy: 0.6879\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8240 - accuracy: 0.7054 - val_loss: 1.7133 - val_accuracy: 0.6879\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8330 - accuracy: 0.7143 - val_loss: 1.5113 - val_accuracy: 0.3262\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1840 - accuracy: 0.6007 - val_loss: 1.1895 - val_accuracy: 0.7092\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.0820 - accuracy: 0.6992 - val_loss: 1.0352 - val_accuracy: 0.7057\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.1389 - accuracy: 0.7196 - val_loss: 1.2983 - val_accuracy: 0.6738\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3715 - accuracy: 0.4862 - val_loss: 1.3086 - val_accuracy: 0.6525\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.9608 - accuracy: 0.6433 - val_loss: 1.0207 - val_accuracy: 0.6489\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8466 - accuracy: 0.6531 - val_loss: 1.1565 - val_accuracy: 0.6738\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8044 - accuracy: 0.6744 - val_loss: 1.4176 - val_accuracy: 0.6915\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.6681 - val_loss: 1.4068 - val_accuracy: 0.6879\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7334 - accuracy: 0.6735 - val_loss: 1.4190 - val_accuracy: 0.6915\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.7152 - val_loss: 0.7569 - val_accuracy: 0.6879\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8782 - accuracy: 0.6415 - val_loss: 0.8290 - val_accuracy: 0.6418\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.1858 - accuracy: 0.6699 - val_loss: 0.9541 - val_accuracy: 0.6383\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.6983 - val_loss: 0.7693 - val_accuracy: 0.7128\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.7054 - val_loss: 1.3921 - val_accuracy: 0.6986\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.7143 - val_loss: 0.8597 - val_accuracy: 0.6986\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.7258 - val_loss: 0.9284 - val_accuracy: 0.7057\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7524 - val_loss: 0.8943 - val_accuracy: 0.7340\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.7445 - val_loss: 0.9005 - val_accuracy: 0.7376\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8118 - accuracy: 0.7205 - val_loss: 1.2042 - val_accuracy: 0.6348\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.0055 - accuracy: 0.6557 - val_loss: 0.8341 - val_accuracy: 0.6596\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.8200 - accuracy: 0.6779 - val_loss: 0.7248 - val_accuracy: 0.6773\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.7116 - val_loss: 0.7438 - val_accuracy: 0.6702\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7849 - accuracy: 0.6788 - val_loss: 0.8531 - val_accuracy: 0.6702\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.6930 - val_loss: 0.8269 - val_accuracy: 0.7305\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7631 - accuracy: 0.7107 - val_loss: 0.8778 - val_accuracy: 0.6560\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7554 - accuracy: 0.5634 - val_loss: 1.9863 - val_accuracy: 0.2376\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7500 - accuracy: 0.5084 - val_loss: 1.5634 - val_accuracy: 0.5603\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6354 - accuracy: 0.5297 - val_loss: 1.5685 - val_accuracy: 0.5567\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6213 - accuracy: 0.5342 - val_loss: 1.5572 - val_accuracy: 0.5603\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6091 - accuracy: 0.5404 - val_loss: 1.5738 - val_accuracy: 0.5745\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5228 - accuracy: 0.5617 - val_loss: 1.4805 - val_accuracy: 0.5745\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.4897 - accuracy: 0.5732 - val_loss: 1.4815 - val_accuracy: 0.5851\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4823 - accuracy: 0.5732 - val_loss: 1.4852 - val_accuracy: 0.5816\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4850 - accuracy: 0.5705 - val_loss: 1.4424 - val_accuracy: 0.5957\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8046 - accuracy: 0.4916 - val_loss: 1.8628 - val_accuracy: 0.5248\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9229 - accuracy: 0.4925 - val_loss: 1.6598 - val_accuracy: 0.5142\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6611 - accuracy: 0.5280 - val_loss: 1.7488 - val_accuracy: 0.5106\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6783 - accuracy: 0.5217 - val_loss: 1.6481 - val_accuracy: 0.5177\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6038 - accuracy: 0.5271 - val_loss: 1.5315 - val_accuracy: 0.5248\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4936 - accuracy: 0.5377 - val_loss: 1.4859 - val_accuracy: 0.5248\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4642 - accuracy: 0.5377 - val_loss: 1.4610 - val_accuracy: 0.5248\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4493 - accuracy: 0.5377 - val_loss: 1.4511 - val_accuracy: 0.5248\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4416 - accuracy: 0.5377 - val_loss: 1.4386 - val_accuracy: 0.5248\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4340 - accuracy: 0.5377 - val_loss: 1.4352 - val_accuracy: 0.5248\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4339 - accuracy: 0.5377 - val_loss: 1.4273 - val_accuracy: 0.5248\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4305 - accuracy: 0.5377 - val_loss: 1.4278 - val_accuracy: 0.5248\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.4293 - accuracy: 0.5377 - val_loss: 1.4262 - val_accuracy: 0.5248\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 18.8151 - accuracy: 0.6096 - val_loss: 1.4279 - val_accuracy: 0.7943\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.9308 - accuracy: 0.8332 - val_loss: 0.7071 - val_accuracy: 0.8404\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8802 - val_loss: 0.9219 - val_accuracy: 0.8582\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.9175 - val_loss: 0.4193 - val_accuracy: 0.9043\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9459 - val_loss: 0.3804 - val_accuracy: 0.9255\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.9663 - val_loss: 0.3355 - val_accuracy: 0.9326\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9574 - val_loss: 0.3138 - val_accuracy: 0.9220\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9610 - val_loss: 0.3930 - val_accuracy: 0.9255\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9636 - val_loss: 0.2404 - val_accuracy: 0.9326\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9840 - val_loss: 0.2455 - val_accuracy: 0.9468\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9787 - val_loss: 0.2353 - val_accuracy: 0.9468\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9823 - val_loss: 0.2005 - val_accuracy: 0.9574\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9911 - val_loss: 0.2075 - val_accuracy: 0.9610\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9911 - val_loss: 0.2325 - val_accuracy: 0.9504\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 0.2022 - val_accuracy: 0.9610\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9920 - val_loss: 0.2463 - val_accuracy: 0.9504\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9938 - val_loss: 0.2325 - val_accuracy: 0.9610\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.2362 - val_accuracy: 0.9645\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.2478 - val_accuracy: 0.9574\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.3747 - val_accuracy: 0.9397\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9867 - val_loss: 0.4917 - val_accuracy: 0.9184\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9618 - val_loss: 0.3976 - val_accuracy: 0.9255\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.9468 - val_loss: 1.3300 - val_accuracy: 0.8901\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.9423 - val_loss: 0.3367 - val_accuracy: 0.9255\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.9361 - val_loss: 0.4741 - val_accuracy: 0.9291\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9583 - val_loss: 0.8145 - val_accuracy: 0.8759\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.9388 - val_loss: 0.2260 - val_accuracy: 0.9504\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9654 - val_loss: 0.2599 - val_accuracy: 0.9610\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9858 - val_loss: 0.3799 - val_accuracy: 0.9397\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9885 - val_loss: 0.3362 - val_accuracy: 0.9468\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: 0.2145 - val_accuracy: 0.9645\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9858 - val_loss: 0.5756 - val_accuracy: 0.9326\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9831 - val_loss: 0.2970 - val_accuracy: 0.9504\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9814 - val_loss: 0.2859 - val_accuracy: 0.9539\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.9494 - val_loss: 0.7132 - val_accuracy: 0.9043\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9379 - val_loss: 0.2456 - val_accuracy: 0.9539\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9743 - val_loss: 0.1290 - val_accuracy: 0.9539\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9849 - val_loss: 0.1700 - val_accuracy: 0.9610\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9876 - val_loss: 0.1756 - val_accuracy: 0.9610\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.1180 - val_accuracy: 0.9681\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.1554 - val_accuracy: 0.9681\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.1403 - val_accuracy: 0.9610\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9929 - val_loss: 0.1412 - val_accuracy: 0.9610\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9929 - val_loss: 0.1412 - val_accuracy: 0.9610\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.1609 - val_accuracy: 0.9610\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.1467 - val_accuracy: 0.9645\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.1350 - val_accuracy: 0.9645\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1373 - val_accuracy: 0.9645\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.1484 - val_accuracy: 0.9645\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.1634 - val_accuracy: 0.9645\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.1820 - val_accuracy: 0.9610\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.1704 - val_accuracy: 0.9645\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.1701 - val_accuracy: 0.9645\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.1730 - val_accuracy: 0.9645\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.1716 - val_accuracy: 0.9645\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.1751 - val_accuracy: 0.9645\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9956 - val_loss: 0.1747 - val_accuracy: 0.9645\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9956 - val_loss: 0.1725 - val_accuracy: 0.9645\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9965 - val_loss: 0.1710 - val_accuracy: 0.9645\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9956 - val_loss: 0.1833 - val_accuracy: 0.9610\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 0.1945 - val_accuracy: 0.9645\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.1908 - val_accuracy: 0.9645\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9965 - val_loss: 0.1876 - val_accuracy: 0.9645\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1965 - val_accuracy: 0.9681\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 0.2193 - val_accuracy: 0.9645\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.1982 - val_accuracy: 0.9716\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9965 - val_loss: 0.2104 - val_accuracy: 0.9681\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.2085 - val_accuracy: 0.9645\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1910 - val_accuracy: 0.9681\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.2662 - val_accuracy: 0.9645\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.3082 - val_accuracy: 0.9645\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9929 - val_loss: 0.3619 - val_accuracy: 0.9574\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9823 - val_loss: 0.2286 - val_accuracy: 0.9610\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9752 - val_loss: 1.4377 - val_accuracy: 0.8262\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.7303 - accuracy: 0.8997 - val_loss: 1.8278 - val_accuracy: 0.8369\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.4925 - accuracy: 0.4747 - val_loss: 3.9887 - val_accuracy: 0.0993\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0065 - accuracy: 0.4082 - val_loss: 1.7194 - val_accuracy: 0.5248\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7297 - accuracy: 0.5102 - val_loss: 1.6679 - val_accuracy: 0.5319\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6972 - accuracy: 0.5164 - val_loss: 1.6346 - val_accuracy: 0.5390\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6506 - accuracy: 0.5280 - val_loss: 1.6227 - val_accuracy: 0.5426\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6457 - accuracy: 0.5280 - val_loss: 1.6170 - val_accuracy: 0.5426\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6436 - accuracy: 0.5280 - val_loss: 1.6187 - val_accuracy: 0.5426\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6412 - accuracy: 0.5280 - val_loss: 1.6165 - val_accuracy: 0.5426\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6393 - accuracy: 0.5280 - val_loss: 1.6156 - val_accuracy: 0.5426\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6383 - accuracy: 0.5280 - val_loss: 1.6139 - val_accuracy: 0.5426\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6379 - accuracy: 0.5280 - val_loss: 1.6139 - val_accuracy: 0.5426\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6377 - accuracy: 0.5280 - val_loss: 1.6138 - val_accuracy: 0.5426\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6378 - accuracy: 0.5280 - val_loss: 1.6151 - val_accuracy: 0.5426\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6368 - accuracy: 0.5280 - val_loss: 1.6131 - val_accuracy: 0.5426\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6361 - accuracy: 0.5280 - val_loss: 1.6141 - val_accuracy: 0.5426\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6363 - accuracy: 0.5280 - val_loss: 1.6135 - val_accuracy: 0.5426\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6371 - accuracy: 0.5280 - val_loss: 1.6141 - val_accuracy: 0.5426\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6371 - accuracy: 0.5280 - val_loss: 1.6119 - val_accuracy: 0.5426\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6358 - accuracy: 0.5280 - val_loss: 1.6128 - val_accuracy: 0.5426\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6357 - accuracy: 0.5280 - val_loss: 1.6123 - val_accuracy: 0.5426\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6353 - accuracy: 0.5280 - val_loss: 1.6122 - val_accuracy: 0.5426\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6357 - accuracy: 0.5280 - val_loss: 1.6133 - val_accuracy: 0.5426\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6349 - accuracy: 0.5280 - val_loss: 1.6132 - val_accuracy: 0.5426\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6353 - accuracy: 0.5280 - val_loss: 1.6142 - val_accuracy: 0.5426\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6358 - accuracy: 0.5280 - val_loss: 1.6132 - val_accuracy: 0.5426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4jnnDPqgmz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "7b4d09c3-af19-4f86-e51d-a53806c0d926"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "layers = ['2','3','4','5']\n",
        "ax.bar(layers,times)\n",
        "print(\"Training Times\")\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Times\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTiBcLAWgmOP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c6354f4b-f083-4da0-952a-0afe2f7ed4ca"
      },
      "source": [
        "print(\"Train and test loss: \")\n",
        "data = [trainAcc,testAcc]\n",
        "X = np.arange(len(layers))\n",
        "fig = plt.figure()\n",
        "ind=np.arange(4)\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "layers = ['2','3','4','5']\n",
        "ax.bar(X + 0.00, data[0], color = 'b', width = 0.25)\n",
        "ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)\n",
        "ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
        "ax.legend(labels=['Train Accuracy','Test Accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train and test loss: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY_8v0duh7kp",
        "colab_type": "text"
      },
      "source": [
        "# So maximum accuracy is obtained for 32 nodes when number of layers are 3"
      ]
    }
  ]
}